"""
ログ整形機能シナリオテスト

実際の使用シナリオに基づいた統合テストを提供します。
"""

from __future__ import annotations

import json

# テスト用のモックヘルパーをインポート
import sys
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch

import pytest
from click.testing import CliRunner
from rich.console import Console

from ci_helper.cli import cli
from ci_helper.core.models import ExecutionResult, Failure, FailureType, JobResult, WorkflowResult
from ci_helper.formatters import get_formatter_manager

sys.path.insert(0, str(Path(__file__).parent.parent))
from tests.utils.mock_helpers import setup_stable_prompt_mock


class TestLogFormattingScenarios:
    """実際の使用シナリオに基づいたテスト"""

    @pytest.fixture
    def complex_execution_result(self) -> ExecutionResult:
        """複雑な実行結果を作成（複数のワークフロー、ジョブ、失敗を含む）"""
        failures_job1 = [
            Failure(
                type=FailureType.ASSERTION,
                message="AssertionError: Expected 200 but got 404",
                file_path="tests/integration/test_api.py",
                line_number=25,
                context_before=["def test_api_endpoint():", "    response = client.get('/api/users')"],
                context_after=["    assert response.json()['users']"],
                stack_trace='Traceback (most recent call last):\n  File "test_api.py", line 25',
            ),
            Failure(
                type=FailureType.ERROR,
                message="ConnectionError: Failed to connect to database",
                file_path="src/database/connection.py",
                line_number=15,
                context_before=["def connect():", "    try:"],
                context_after=["    except Exception as e:", "        raise ConnectionError(str(e))"],
                stack_trace='Traceback (most recent call last):\n  File "connection.py", line 15',
            ),
        ]

        failures_job2 = [
            Failure(
                type=FailureType.SYNTAX,
                message="SyntaxError: invalid syntax",
                file_path="src/utils/parser.py",
                line_number=42,
                context_before=["def parse_config(data):", "    if data:"],
                context_after=["        return parsed_data"],
                stack_trace=None,
            ),
        ]

        job1 = JobResult(name="test", success=False, failures=failures_job1, duration=120.5)
        job2 = JobResult(name="lint", success=False, failures=failures_job2, duration=30.2)
        job3 = JobResult(name="build", success=True, failures=[], duration=180.0)

        workflow1 = WorkflowResult(name="ci.yml", success=False, jobs=[job1, job2], duration=150.7)
        workflow2 = WorkflowResult(name="deploy.yml", success=True, jobs=[job3], duration=180.0)

        return ExecutionResult(success=False, workflows=[workflow1, workflow2], total_duration=330.7)

    @pytest.fixture
    def empty_execution_result(self) -> ExecutionResult:
        """空の実行結果（失敗なし）"""
        job = JobResult(name="test", success=True, failures=[], duration=45.0)
        workflow = WorkflowResult(name="test.yml", success=True, jobs=[job], duration=45.0)

        return ExecutionResult(success=True, workflows=[workflow], total_duration=45.0)

    def test_ai_format_with_complex_failures(self, complex_execution_result: ExecutionResult):
        """AI形式での複雑な失敗パターンの整形テスト"""
        formatter_manager = get_formatter_manager()

        output = formatter_manager.format_log(complex_execution_result, "ai")

        # AI形式の必須要素が含まれていることを確認
        assert "# CI Failure Report" in output or "## " in output
        assert "AssertionError" in output
        assert "ConnectionError" in output
        assert "SyntaxError" in output

        # ファイルパスと行番号が含まれていることを確認
        assert "test_api.py" in output
        assert "connection.py" in output
        assert "parser.py" in output

        # コンテキスト情報が含まれていることを確認
        assert "def test_api_endpoint" in output or "test_api_endpoint" in output

    def test_human_format_with_rich_markup(self, complex_execution_result: ExecutionResult):
        """人間可読形式でのRichマークアップテスト"""
        formatter_manager = get_formatter_manager()

        output = formatter_manager.format_log(complex_execution_result, "human")

        # Rich マークアップが含まれていることを確認
        assert "[" in output and "]" in output

        # 色付けマークアップの例
        rich_patterns = ["[red]", "[green]", "[yellow]", "[cyan]", "[bold]", "[dim]"]
        has_rich_markup = any(pattern in output for pattern in rich_patterns)
        assert has_rich_markup, "Rich マークアップが見つかりません"

    def test_json_format_structure_validation(self, complex_execution_result: ExecutionResult):
        """JSON形式の構造検証テスト"""
        formatter_manager = get_formatter_manager()

        output = formatter_manager.format_log(complex_execution_result, "json")

        # 有効なJSONであることを確認
        try:
            data = json.loads(output)
        except json.JSONDecodeError as e:
            pytest.fail(f"無効なJSON出力: {e}")

        # 必須フィールドの存在確認
        assert "execution_summary" in data
        assert "workflows" in data
        assert "all_failures" in data

        # execution_summary内の必須フィールド確認
        assert "success" in data["execution_summary"]
        assert "total_duration" in data["execution_summary"]

        # ワークフローデータの構造確認
        assert isinstance(data["workflows"], list)
        assert len(data["workflows"]) == 2

        # 失敗情報の構造確認
        workflow = data["workflows"][0]
        assert "jobs" in workflow
        assert isinstance(workflow["jobs"], list)

        job = workflow["jobs"][0]
        assert "failures" in job
        assert isinstance(job["failures"], list)

        if job["failures"]:
            failure = job["failures"][0]
            assert "type" in failure
            assert "message" in failure

    def test_empty_result_formatting(self, empty_execution_result: ExecutionResult):
        """空の結果（失敗なし）の整形テスト"""
        formatter_manager = get_formatter_manager()

        # 各フォーマットで空の結果を処理
        ai_output = formatter_manager.format_log(empty_execution_result, "ai")
        human_output = formatter_manager.format_log(empty_execution_result, "human")
        json_output = formatter_manager.format_log(empty_execution_result, "json")

        # 出力が生成されることを確認
        assert ai_output.strip()
        assert human_output.strip()
        assert json_output.strip()

        # 成功状態が反映されることを確認
        assert "成功" in ai_output or "Success" in ai_output or "✓" in ai_output

        # JSONの成功フラグ確認
        json_data = json.loads(json_output)
        assert json_data["success"] is True

    @patch("ci_helper.commands.format_logs._get_execution_result")
    def test_command_line_with_filter_options(self, mock_get_result: Mock, complex_execution_result: ExecutionResult):
        """コマンドラインでのフィルターオプションテスト"""
        mock_get_result.return_value = complex_execution_result

        runner = CliRunner()

        with patch("ci_helper.commands.format_logs.get_formatter_manager") as mock_manager:
            mock_formatter_manager = Mock()
            mock_formatter_manager.format_log.return_value = "Filtered output"
            mock_manager.return_value = mock_formatter_manager

            with patch("ci_helper.commands.format_logs.get_progress_manager") as mock_progress:
                mock_progress_manager = Mock()
                mock_progress_manager.execute_with_progress.return_value = "Filtered output"
                mock_progress.return_value = mock_progress_manager

                # エラーフィルタリングオプション付きで実行
                result = runner.invoke(
                    cli, ["format-logs", "--format", "ai", "--filter-errors", "--verbose-level", "detailed"]
                )

                assert result.exit_code == 0

                # フォーマッターが正しいオプションで呼び出されることを確認
                call_args = mock_formatter_manager.format_log.call_args
                assert call_args[1]["filter_errors"] is True
                assert call_args[1]["verbose_level"] == "detailed"

    def test_format_consistency_with_different_options(self, complex_execution_result: ExecutionResult):
        """異なるオプションでのフォーマット一貫性テスト"""
        formatter_manager = get_formatter_manager()

        # 基本オプション
        basic_output = formatter_manager.format_log(
            complex_execution_result, "ai", filter_errors=False, verbose_level="normal"
        )

        # 詳細オプション
        detailed_output = formatter_manager.format_log(
            complex_execution_result, "ai", filter_errors=False, verbose_level="detailed"
        )

        # エラーフィルタリングオプション
        filtered_output = formatter_manager.format_log(
            complex_execution_result, "ai", filter_errors=True, verbose_level="normal"
        )

        # 各出力が生成されることを確認
        assert basic_output.strip()
        assert detailed_output.strip()
        assert filtered_output.strip()

        # 詳細レベルによって出力量が変わることを確認
        # （詳細版の方が長い、またはより多くの情報を含む）
        assert len(detailed_output) >= len(basic_output) or "詳細" in detailed_output

    @patch("ci_helper.commands.format_logs._get_execution_result")
    def test_file_output_integration(self, mock_get_result: Mock, complex_execution_result: ExecutionResult):
        """ファイル出力統合テスト"""
        mock_get_result.return_value = complex_execution_result

        runner = CliRunner()

        with tempfile.TemporaryDirectory() as temp_dir:
            output_file = Path(temp_dir) / "formatted_output.md"

            with patch("ci_helper.commands.format_logs.get_formatter_manager") as mock_manager:
                mock_formatter_manager = Mock()
                mock_formatter_manager.format_log.return_value = "# Formatted Content\n\nTest output"
                mock_manager.return_value = mock_formatter_manager

                with patch("ci_helper.commands.format_logs.get_progress_manager") as mock_progress:
                    mock_progress_manager = Mock()
                    mock_progress_manager.execute_with_progress.return_value = "# Formatted Content\n\nTest output"
                    mock_progress.return_value = mock_progress_manager

                    with patch("ci_helper.utils.file_save_utils.FileSaveManager.save_formatted_log") as mock_save:
                        mock_save.return_value = (True, str(output_file))

                        result = runner.invoke(
                            cli, ["format-logs", "--format", "ai", "--output", str(output_file), "--no-confirm"]
                        )

                        assert result.exit_code == 0
                        mock_save.assert_called_once()

                        # 保存パラメータの確認
                        call_args = mock_save.call_args
                        assert call_args[1]["content"] == "# Formatted Content\n\nTest output"
                        assert call_args[1]["format_type"] == "ai"

    def test_error_handling_with_invalid_log_data(self):
        """無効なログデータでのエラーハンドリングテスト"""
        formatter_manager = get_formatter_manager()

        # 不正な実行結果オブジェクト
        invalid_result = ExecutionResult(
            success=None,  # 不正な値
            workflows=None,  # 不正な値
            total_duration=-1.0,  # 不正な値
        )

        # フォーマッターがエラーを適切に処理することを確認
        try:
            output = formatter_manager.format_log(invalid_result, "ai")
            # エラーが発生しない場合は、何らかの出力が生成されることを確認
            assert output is not None
        except Exception as e:
            # エラーが発生する場合は、適切なエラーメッセージであることを確認
            assert isinstance(e, (ValueError, TypeError, AttributeError))

    @patch("rich.prompt.Prompt.ask")
    def test_menu_navigation_with_back_operations(self, mock_prompt: Mock):
        """メニューナビゲーションでの戻る操作テスト"""
        from ci_helper.ui.command_menus import CommandMenuBuilder
        from ci_helper.ui.menu_system import MenuSystem

        console = Console()
        command_handlers = {
            "format_logs": Mock(return_value=True),
        }

        builder = CommandMenuBuilder(console, command_handlers)
        menu_system = MenuSystem(console)

        # 深いメニューナビゲーションと戻る操作
        # ログ管理 → ログ整形 → 最新ログ整形 → AI形式 → 戻る → 戻る → 戻る → 終了
        # 安定したモック設定を使用してStopIterationエラーを防ぐ
        setup_stable_prompt_mock(mock_prompt, ["5", "4", "1", "1", "", "b", "b", "b", "b", "q"])

        main_menu = builder.build_main_menu()

        with patch.object(menu_system, "console") as mock_console:
            mock_console.clear = Mock()
            mock_console.print = Mock()

            # メニューシステムが正常に動作することを確認
            menu_system.run_menu(main_menu)

        # コマンドが実行されることを確認
        command_handlers["format_logs"].assert_called_once()

    def test_performance_with_large_failure_set(self):
        """大量の失敗データでのパフォーマンステスト"""
        import time

        # 大量の失敗を含む実行結果を作成
        failures = []
        for i in range(100):  # 100個の失敗
            failures.append(
                Failure(
                    type=FailureType.ERROR,
                    message=f"Error {i}: Test failure message",
                    file_path=f"test_file_{i}.py",
                    line_number=i + 1,
                    context_before=[f"line {i}", f"line {i + 1}"],
                    context_after=[f"line {i + 3}", f"line {i + 4}"],
                    stack_trace=f"Traceback for error {i}",
                )
            )

        job = JobResult(name="test", success=False, failures=failures, duration=300.0)
        workflow = WorkflowResult(name="test.yml", success=False, jobs=[job], duration=300.0)
        large_result = ExecutionResult(success=False, workflows=[workflow], total_duration=300.0)

        formatter_manager = get_formatter_manager()

        # 各フォーマットでの処理時間を測定
        formats = ["ai", "human", "json"]

        for format_type in formats:
            start_time = time.time()
            output = formatter_manager.format_log(large_result, format_type)
            end_time = time.time()

            processing_time = end_time - start_time

            # 出力が生成されることを確認
            assert output.strip()

            # 処理時間が合理的な範囲内であることを確認（10秒以内）
            assert processing_time < 10.0, f"{format_type}フォーマットの処理時間が長すぎます: {processing_time}秒"

    def test_concurrent_formatting_safety(self, complex_execution_result: ExecutionResult):
        """並行フォーマット処理の安全性テスト"""
        import threading

        formatter_manager = get_formatter_manager()
        results = []
        errors = []

        def format_task(format_type: str):
            try:
                output = formatter_manager.format_log(complex_execution_result, format_type)
                results.append((format_type, output))
            except Exception as e:
                errors.append((format_type, e))

        # 複数のスレッドで同時にフォーマット処理を実行
        threads = []
        for format_type in ["ai", "human", "json"]:
            thread = threading.Thread(target=format_task, args=(format_type,))
            threads.append(thread)
            thread.start()

        # すべてのスレッドの完了を待機
        for thread in threads:
            thread.join()

        # エラーが発生していないことを確認
        assert not errors, f"並行処理でエラーが発生しました: {errors}"

        # すべてのフォーマットで結果が生成されることを確認
        assert len(results) == 3

        # 各結果が有効であることを確認
        for format_type, output in results:
            assert output.strip(), f"{format_type}フォーマットの出力が空です"
