# ã‚«ãƒãƒ¬ãƒƒã‚¸ç¶­æŒã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€CI-Helperãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ã®é•·æœŸçš„ãªç¶­æŒã¨æ”¹å–„ã®ãŸã‚ã®æŒ‡é‡ã‚’æä¾›ã—ã¾ã™ã€‚70%ä»¥ä¸Šã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŒç¶šçš„ã«ç¶­æŒã—ã€æ–°æ©Ÿèƒ½è¿½åŠ æ™‚ã«ã‚‚ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ä¸‹ã—ãªã„ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ã‚«ãƒãƒ¬ãƒƒã‚¸ç¶­æŒã®åŸºæœ¬æˆ¦ç•¥

### 1. ç¶™ç¶šçš„ç›£è¦–

#### CI/CDã§ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯

```yaml
# .github/workflows/test.yml
name: Test and Coverage
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install uv
          uv sync

      - name: Run tests with coverage
        run: |
          uv run pytest --cov=ci_helper --cov-report=xml --cov-fail-under=70

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
```

#### ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã§ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª

```bash
# åŸºæœ¬çš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
uv run pytest --cov=ci_helper --cov-report=term-missing

# HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
uv run pytest --cov=ci_helper --cov-report=html
open htmlcov/index.html

# ç‰¹å®šã®é–¾å€¤ã§ã®ãƒ†ã‚¹ãƒˆ
uv run pytest --cov=ci_helper --cov-fail-under=70
```

### 2. æ–°æ©Ÿèƒ½é–‹ç™ºæ™‚ã®ã‚«ãƒãƒ¬ãƒƒã‚¸æˆ¦ç•¥

#### æ©Ÿèƒ½è¿½åŠ å‰ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç¢ºç«‹

```bash
# ç¾åœ¨ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’è¨˜éŒ²
uv run pytest --cov=ci_helper --cov-report=json
cp coverage.json baseline_coverage.json
```

#### æ–°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆè¦ä»¶

æ–°ã—ã„æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®åŸºæº–ã‚’æº€ãŸã™ãƒ†ã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹ï¼š

```python
# æ–°æ©Ÿèƒ½: ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’æ©Ÿèƒ½
class PatternLearner:
    def learn_from_feedback(self, feedback_data):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’"""
        pass

    def update_pattern_weights(self, pattern_id, weight_delta):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é‡ã¿ã‚’æ›´æ–°"""
        pass

# å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆï¼ˆæœ€ä½é™ã®è¦ä»¶ï¼‰
class TestPatternLearner:
    def test_learn_from_valid_feedback(self):
        """æœ‰åŠ¹ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ"""
        learner = PatternLearner()
        feedback = {"pattern_id": "test", "success": True, "confidence": 0.8}

        result = learner.learn_from_feedback(feedback)

        assert result.patterns_updated > 0
        assert result.learning_score > 0.5

    def test_learn_from_invalid_feedback(self):
        """ç„¡åŠ¹ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        learner = PatternLearner()

        with pytest.raises(InvalidFeedbackError):
            learner.learn_from_feedback({"invalid": "data"})

    def test_update_pattern_weights_boundary_values(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³é‡ã¿æ›´æ–°ã®å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ"""
        learner = PatternLearner()

        # æœ€å¤§å€¤ã§ã®æ›´æ–°
        result = learner.update_pattern_weights("test", 1.0)
        assert result.new_weight <= 1.0

        # æœ€å°å€¤ã§ã®æ›´æ–°
        result = learner.update_pattern_weights("test", -1.0)
        assert result.new_weight >= 0.0
```

### 3. ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹ã®æ—©æœŸæ¤œå‡º

#### ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã®ã‚«ãƒãƒ¬ãƒƒã‚¸å·®åˆ†ãƒã‚§ãƒƒã‚¯

```python
# scripts/check_coverage_diff.py
import json
import sys

def check_coverage_diff(baseline_file, current_file, threshold=-2.0):
    """ã‚«ãƒãƒ¬ãƒƒã‚¸ã®å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯"""
    with open(baseline_file) as f:
        baseline = json.load(f)

    with open(current_file) as f:
        current = json.load(f)

    baseline_total = baseline['totals']['percent_covered']
    current_total = current['totals']['percent_covered']

    diff = current_total - baseline_total

    if diff < threshold:
        print(f"âŒ ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ{abs(diff):.1f}%ä½ä¸‹ã—ã¾ã—ãŸ")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_total:.1f}%")
        print(f"ç¾åœ¨: {current_total:.1f}%")

        # ä½ä¸‹ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‰¹å®š
        for filename, current_data in current['files'].items():
            if filename in baseline['files']:
                baseline_coverage = baseline['files'][filename]['summary']['percent_covered']
                current_coverage = current_data['summary']['percent_covered']
                module_diff = current_coverage - baseline_coverage

                if module_diff < -5.0:  # 5%ä»¥ä¸Šã®ä½ä¸‹
                    print(f"  ğŸ“‰ {filename}: {module_diff:.1f}%")

        sys.exit(1)
    else:
        print(f"âœ… ã‚«ãƒãƒ¬ãƒƒã‚¸: {current_total:.1f}% (å¤‰åŒ–: {diff:+.1f}%)")

if __name__ == "__main__":
    check_coverage_diff("baseline_coverage.json", "coverage.json")
```

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ç®¡ç†

### 1. å„ªå…ˆåº¦åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™

```python
# coverage_targets.py
COVERAGE_TARGETS = {
    # é«˜å„ªå…ˆåº¦: ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
    "src/ci_helper/ai/pattern_engine.py": 85,
    "src/ci_helper/ai/fix_generator.py": 80,
    "src/ci_helper/ai/risk_calculator.py": 80,

    # ä¸­å„ªå…ˆåº¦: è¨­å®šãƒ»ç®¡ç†
    "src/ci_helper/ai/auto_fix_config.py": 70,
    "src/ci_helper/ai/settings_manager.py": 70,
    "src/ci_helper/ai/custom_pattern_manager.py": 65,

    # ä½å„ªå…ˆåº¦: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    "src/ci_helper/formatters/streaming_formatter.py": 50,
    "src/ci_helper/utils/log_compressor.py": 45,

    # é™¤å¤–å¯¾è±¡: ä¸»ã«ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
    "src/ci_helper/ai/models.py": 30,
    "src/ci_helper/cli.py": 40,  # CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
}

def check_module_coverage(coverage_data):
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™ã®é”æˆçŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
    issues = []

    for module_path, target in COVERAGE_TARGETS.items():
        if module_path in coverage_data['files']:
            actual = coverage_data['files'][module_path]['summary']['percent_covered']
            if actual < target:
                issues.append({
                    'module': module_path,
                    'target': target,
                    'actual': actual,
                    'gap': target - actual
                })

    return issues
```

### 2. ã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ã®å„ªå…ˆé †ä½ä»˜ã‘

```python
def prioritize_coverage_improvements(coverage_data, targets):
    """ã‚«ãƒãƒ¬ãƒƒã‚¸æ”¹å–„ã®å„ªå…ˆé †ä½ã‚’è¨ˆç®—"""
    improvements = []

    for module_path, target in targets.items():
        if module_path in coverage_data['files']:
            file_data = coverage_data['files'][module_path]
            actual = file_data['summary']['percent_covered']

            if actual < target:
                # å½±éŸ¿åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                lines_of_code = file_data['summary']['num_statements']
                coverage_gap = target - actual

                # å„ªå…ˆåº¦ = (ã‚³ãƒ¼ãƒ‰è¡Œæ•° Ã— ã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³) / 100
                priority_score = (lines_of_code * coverage_gap) / 100

                improvements.append({
                    'module': module_path,
                    'priority_score': priority_score,
                    'lines_of_code': lines_of_code,
                    'coverage_gap': coverage_gap,
                    'current_coverage': actual,
                    'target_coverage': target
                })

    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    return sorted(improvements, key=lambda x: x['priority_score'], reverse=True)
```

## ãƒ†ã‚¹ãƒˆå“è³ªã®ç¶­æŒ

### 1. ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# scripts/analyze_test_quality.py
import ast
import os
from pathlib import Path

class TestQualityAnalyzer:
    def __init__(self, test_directory="tests"):
        self.test_directory = Path(test_directory)

    def analyze_test_file(self, file_path):
        """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªã‚’åˆ†æ"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        tree = ast.parse(content)

        metrics = {
            'test_methods': 0,
            'assertions': 0,
            'mocks': 0,
            'fixtures': 0,
            'docstrings': 0,
            'lines_of_code': len(content.splitlines())
        }

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name.startswith('test_'):
                    metrics['test_methods'] += 1
                    if ast.get_docstring(node):
                        metrics['docstrings'] += 1

                # ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã®æ¤œå‡º
                for decorator in node.decorator_list:
                    if (isinstance(decorator, ast.Name) and
                        decorator.id == 'fixture'):
                        metrics['fixtures'] += 1

            # ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
            elif isinstance(node, ast.Assert):
                metrics['assertions'] += 1

            # ãƒ¢ãƒƒã‚¯ã®æ¤œå‡º
            elif (isinstance(node, ast.Call) and
                  isinstance(node.func, ast.Name) and
                  'mock' in node.func.id.lower()):
                metrics['mocks'] += 1

        return metrics

    def calculate_quality_score(self, metrics):
        """ãƒ†ã‚¹ãƒˆå“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if metrics['test_methods'] == 0:
            return 0

        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é‡ã¿ä»˜ã‘ã‚¹ã‚³ã‚¢
        assertion_ratio = metrics['assertions'] / metrics['test_methods']
        docstring_ratio = metrics['docstrings'] / metrics['test_methods']

        # å“è³ªã‚¹ã‚³ã‚¢ (0-100)
        score = (
            min(assertion_ratio * 20, 40) +  # ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³å¯†åº¦ (æœ€å¤§40ç‚¹)
            docstring_ratio * 30 +           # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç‡ (æœ€å¤§30ç‚¹)
            min(metrics['fixtures'] * 5, 20) + # ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ä½¿ç”¨ (æœ€å¤§20ç‚¹)
            min(metrics['mocks'] * 2, 10)    # ãƒ¢ãƒƒã‚¯ä½¿ç”¨ (æœ€å¤§10ç‚¹)
        )

        return min(score, 100)
```

### 2. ãƒ†ã‚¹ãƒˆã®é‡è¤‡æ¤œå‡º

```python
def detect_duplicate_tests(test_directory):
    """é‡è¤‡ã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’æ¤œå‡º"""
    test_files = list(Path(test_directory).rglob("test_*.py"))

    # ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    similar_tests = []

    for file1 in test_files:
        for file2 in test_files:
            if file1 >= file2:  # åŒã˜ãƒšã‚¢ã‚’2å›ãƒã‚§ãƒƒã‚¯ã—ãªã„
                continue

            similarity = calculate_test_similarity(file1, file2)
            if similarity > 0.8:  # 80%ä»¥ä¸Šã®é¡ä¼¼åº¦
                similar_tests.append({
                    'file1': file1,
                    'file2': file2,
                    'similarity': similarity
                })

    return similar_tests

def calculate_test_similarity(file1, file2):
    """2ã¤ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    # ç°¡å˜ãªå®Ÿè£…ä¾‹ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ï¼‰
    with open(file1) as f1, open(file2) as f2:
        content1 = set(f1.read().split())
        content2 = set(f2.read().split())

    intersection = len(content1 & content2)
    union = len(content1 | content2)

    return intersection / union if union > 0 else 0
```

## è‡ªå‹•åŒ–ã¨ãƒ„ãƒ¼ãƒ«

### 1. ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆ

```python
# scripts/generate_coverage_report.py
import subprocess
import json
from datetime import datetime
from pathlib import Path

def generate_comprehensive_coverage_report():
    """åŒ…æ‹¬çš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

    # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ã®åé›†
    subprocess.run([
        "uv", "run", "pytest",
        "--cov=ci_helper",
        "--cov-report=json",
        "--cov-report=html",
        "--cov-report=term"
    ])

    # JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open("coverage.json") as f:
        coverage_data = json.load(f)

    # ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    report = {
        "timestamp": datetime.now().isoformat(),
        "overall_coverage": coverage_data["totals"]["percent_covered"],
        "total_lines": coverage_data["totals"]["num_statements"],
        "covered_lines": coverage_data["totals"]["covered_lines"],
        "missing_lines": coverage_data["totals"]["missing_lines"],
        "modules": []
    }

    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥è©³ç´°
    for filename, file_data in coverage_data["files"].items():
        module_info = {
            "name": filename,
            "coverage": file_data["summary"]["percent_covered"],
            "lines": file_data["summary"]["num_statements"],
            "missing_lines": file_data["missing_lines"],
            "priority": get_module_priority(filename)
        }
        report["modules"].append(module_info)

    # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
    report["modules"].sort(key=lambda x: (x["priority"], -x["coverage"]))

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
    report_path = Path("coverage_report.json")
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2)

    # Markdownãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
    generate_markdown_report(report)

    return report

def generate_markdown_report(report_data):
    """Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    markdown = f"""# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: {report_data['timestamp']}

## å…¨ä½“ã‚µãƒãƒªãƒ¼

- **å…¨ä½“ã‚«ãƒãƒ¬ãƒƒã‚¸**: {report_data['overall_coverage']:.1f}%
- **ç·è¡Œæ•°**: {report_data['total_lines']:,}
- **ã‚«ãƒãƒ¼æ¸ˆã¿è¡Œæ•°**: {report_data['covered_lines']:,}
- **æœªã‚«ãƒãƒ¼è¡Œæ•°**: {report_data['missing_lines']:,}

## ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥è©³ç´°

| ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | ã‚«ãƒãƒ¬ãƒƒã‚¸ | è¡Œæ•° | å„ªå…ˆåº¦ | çŠ¶æ…‹ |
|-----------|-----------|------|--------|------|
"""

    for module in report_data["modules"]:
        status = "âœ…" if module["coverage"] >= 70 else "âš ï¸" if module["coverage"] >= 50 else "âŒ"
        markdown += f"| {module['name']} | {module['coverage']:.1f}% | {module['lines']} | {module['priority']} | {status} |\n"

    markdown += f"""
## æ”¹å–„ææ¡ˆ

### é«˜å„ªå…ˆåº¦ï¼ˆå³åº§ã«å¯¾å¿œï¼‰
"""

    high_priority_modules = [m for m in report_data["modules"]
                           if m["priority"] == "high" and m["coverage"] < 70]

    for module in high_priority_modules[:5]:  # ä¸Šä½5ã¤
        markdown += f"- **{module['name']}**: {module['coverage']:.1f}% â†’ ç›®æ¨™80%\n"

    with open("coverage_report.md", "w", encoding="utf-8") as f:
        f.write(markdown)

def get_module_priority(filename):
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å„ªå…ˆåº¦ã‚’åˆ¤å®š"""
    if any(keyword in filename for keyword in ["pattern_engine", "fix_generator", "risk_calculator"]):
        return "high"
    elif any(keyword in filename for keyword in ["config", "settings", "manager"]):
        return "medium"
    else:
        return "low"
```

### 2. å®šæœŸçš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ç›£è¦–

```bash
#!/bin/bash
# scripts/weekly_coverage_check.sh

echo "ğŸ” é€±æ¬¡ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹..."

# ç¾åœ¨ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æ¸¬å®š
uv run pytest --cov=ci_helper --cov-report=json --quiet

# å‰é€±ã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒ
if [ -f "weekly_coverage_history.json" ]; then
    python scripts/compare_weekly_coverage.py
else
    echo "ğŸ“Š åˆå›å®Ÿè¡Œ: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆä¸­..."
fi

# å±¥æ­´ã«è¿½åŠ 
python scripts/update_coverage_history.py

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python scripts/generate_coverage_report.py

echo "âœ… é€±æ¬¡ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯å®Œäº†"
echo "ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: coverage_report.md"
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒçªç„¶ä½ä¸‹ã—ãŸå ´åˆ

```python
def diagnose_coverage_drop(baseline_file, current_file):
    """ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹ã®åŸå› ã‚’è¨ºæ–­"""

    with open(baseline_file) as f:
        baseline = json.load(f)
    with open(current_file) as f:
        current = json.load(f)

    print("ğŸ” ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹ã®è¨ºæ–­çµæœ:")

    # 1. æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ãªã—ï¼‰
    new_files = set(current['files'].keys()) - set(baseline['files'].keys())
    if new_files:
        print(f"\nğŸ“ æ–°è¦è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ†ã‚¹ãƒˆãªã—ï¼‰:")
        for file in new_files:
            coverage = current['files'][file]['summary']['percent_covered']
            print(f"  - {file}: {coverage:.1f}%")

    # 2. ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒå¤§å¹…ã«ä½ä¸‹ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«
    print(f"\nğŸ“‰ ã‚«ãƒãƒ¬ãƒƒã‚¸ä½ä¸‹ãƒ•ã‚¡ã‚¤ãƒ«:")
    for filename in baseline['files']:
        if filename in current['files']:
            old_coverage = baseline['files'][filename]['summary']['percent_covered']
            new_coverage = current['files'][filename]['summary']['percent_covered']
            diff = new_coverage - old_coverage

            if diff < -10:  # 10%ä»¥ä¸Šã®ä½ä¸‹
                print(f"  - {filename}: {old_coverage:.1f}% â†’ {new_coverage:.1f}% ({diff:.1f}%)")

    # 3. å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
    deleted_files = set(baseline['files'].keys()) - set(current['files'].keys())
    if deleted_files:
        print(f"\nğŸ—‘ï¸ å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for file in deleted_files:
            print(f"  - {file}")
```

### 2. ãƒ†ã‚¹ãƒˆãŒé€šã‚‰ãªã„å ´åˆã®å¯¾å‡¦

```python
def fix_failing_tests():
    """å¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆã®è‡ªå‹•ä¿®æ­£ã‚’è©¦è¡Œ"""

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã—ã¦å¤±æ•—ã‚’åé›†
    result = subprocess.run([
        "uv", "run", "pytest", "--tb=short", "-v"
    ], capture_output=True, text=True)

    if result.returncode != 0:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—ã‚’æ¤œå‡º:")
        print(result.stdout)

        # ã‚ˆãã‚ã‚‹å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è‡ªå‹•ä¿®æ­£
        if "ImportError" in result.stdout:
            print("ğŸ”§ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ã‚’è©¦è¡Œ...")
            fix_import_errors()

        if "AssertionError" in result.stdout:
            print("ğŸ”§ ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã®åˆ†æ...")
            analyze_assertion_errors(result.stdout)

        if "fixture" in result.stdout:
            print("ğŸ”§ ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ã‚’è©¦è¡Œ...")
            fix_fixture_errors()

def fix_import_errors():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•ä¿®æ­£"""
    # __init__.py ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨ä½œæˆ
    test_dirs = Path("tests").rglob("*/")
    for test_dir in test_dirs:
        if test_dir.is_dir():
            init_file = test_dir / "__init__.py"
            if not init_file.exists():
                init_file.touch()
                print(f"  âœ… ä½œæˆ: {init_file}")
```

## ã¾ã¨ã‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã†ã“ã¨ã§ï¼š

1. **æŒç¶šçš„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ç¶­æŒ**: 70%ä»¥ä¸Šã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’é•·æœŸçš„ã«ç¶­æŒ
2. **å“è³ªé‡è¦–ã®é–‹ç™º**: ã‚«ãƒãƒ¬ãƒƒã‚¸æ•°å€¤ã ã‘ã§ãªãã€ãƒ†ã‚¹ãƒˆã®å“è³ªã‚‚å‘ä¸Š
3. **åŠ¹ç‡çš„ãªæ”¹å–„**: å„ªå…ˆåº¦ã«åŸºã¥ã„ãŸæˆ¦ç•¥çš„ãªãƒ†ã‚¹ãƒˆè¿½åŠ 
4. **è‡ªå‹•åŒ–ã«ã‚ˆã‚‹è² è·è»½æ¸›**: æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ã‚’æœ€å°é™ã«æŠ‘åˆ¶

æ–°æ©Ÿèƒ½é–‹ç™ºæ™‚ã¯å¿…ãšã“ã®ã‚¬ã‚¤ãƒ‰ã‚’å‚ç…§ã—ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ã®ç¶­æŒã¨å‘ä¸Šã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚
