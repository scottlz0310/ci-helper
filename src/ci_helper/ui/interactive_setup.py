"""
å¯¾è©±çš„åˆæœŸè¨­å®š

AIãƒ¢ãƒ‡ãƒ«é¸æŠã¨APIã‚­ãƒ¼æ¤œè¨¼ã‚’å«ã‚€å¯¾è©±çš„ãªåˆæœŸè¨­å®šæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

from __future__ import annotations

import os
from typing import Any

from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.table import Table
from rich.text import Text

from ..utils.ai_validator import SUPPORTED_PROVIDERS, AIProviderValidator, ValidationResult


class InteractiveSetup:
    """å¯¾è©±çš„åˆæœŸè¨­å®šã‚¯ãƒ©ã‚¹"""

    def __init__(self, console: Console | None = None):
        """åˆæœŸåŒ–

        Args:
            console: Rich Console ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.console = console or Console()
        self.validator = AIProviderValidator(self.console)
        self.selected_providers: list[str] = []
        self.selected_models: dict[str, str] = {}
        self.validation_results: dict[str, ValidationResult] = {}

    async def run_interactive_setup(self) -> dict[str, Any]:
        """å¯¾è©±çš„åˆæœŸè¨­å®šã‚’å®Ÿè¡Œ

        Returns:
            è¨­å®šæƒ…å ±ã®è¾æ›¸
        """
        self.console.print(
            Panel(Text("CI-Helper å¯¾è©±çš„åˆæœŸè¨­å®š", style="bold magenta"), expand=False, border_style="magenta")
        )
        self.console.print()

        # ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
        self._show_environment_status()

        # ã‚¹ãƒ†ãƒƒãƒ—2: AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®æ¤œè¨¼
        await self._validate_providers()

        # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
        self._select_providers_and_models()

        # ã‚¹ãƒ†ãƒƒãƒ—4: è¿½åŠ è¨­å®š
        additional_config = self._configure_additional_settings()

        # ã‚¹ãƒ†ãƒƒãƒ—5: è¨­å®šã®ç¢ºèª
        config = self._build_configuration(additional_config)
        self._show_configuration_summary(config)

        if Confirm.ask("\n[bold green]ã“ã®è¨­å®šã§ci-helper.tomlã‚’ç”Ÿæˆã—ã¾ã™ã‹ï¼Ÿ[/bold green]"):
            return config
        else:
            self.console.print("[yellow]è¨­å®šã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚[/yellow]")
            return {}

    def _show_environment_status(self) -> None:
        """ç’°å¢ƒå¤‰æ•°ã®çŠ¶æ³ã‚’è¡¨ç¤º"""
        self.console.print("[bold blue]ğŸ“‹ ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª[/bold blue]\n")

        # GitHub ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºèª
        github_tokens = ["GITHUB_TOKEN", "GITHUB_PERSONAL_ACCESS_TOKEN", "GH_TOKEN"]
        github_token_found = None

        for token_name in github_tokens:
            if token_name in os.environ:
                github_token_found = token_name
                break

        if github_token_found:
            self.console.print(f"[green]âœ“[/green] GitHub ãƒˆãƒ¼ã‚¯ãƒ³: {github_token_found}")
        else:
            self.console.print("[yellow]âš [/yellow] GitHub ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            self.console.print("  [dim]GitHub Actionsã®å®Ÿè¡Œã«ã¯å¿…è¦ã§ã™[/dim]")

        # AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®APIã‚­ãƒ¼ç¢ºèª
        for _provider_name, provider_info in SUPPORTED_PROVIDERS.items():
            if provider_info.requires_api_key:
                api_key_exists = bool(os.getenv(provider_info.api_key_env))
                if api_key_exists:
                    self.console.print(
                        f"[green]âœ“[/green] {provider_info.display_name} APIã‚­ãƒ¼: {provider_info.api_key_env}"
                    )
                else:
                    self.console.print(f"[dim]â—‹[/dim] {provider_info.display_name} APIã‚­ãƒ¼: æœªè¨­å®š")

        self.console.print()

    async def _validate_providers(self) -> None:
        """AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’æ¤œè¨¼"""
        self.console.print("[bold blue]ğŸ¤– AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®æ¤œè¨¼ä¸­...[/bold blue]\n")

        # ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’æ¤œè¨¼
        self.validation_results = await self.validator.validate_all_providers()

        # çµæœã‚’è¡¨ç¤º
        for provider_name, result in self.validation_results.items():
            provider_info = SUPPORTED_PROVIDERS[provider_name]

            if result.is_valid:
                self.console.print(f"[green]âœ“[/green] {provider_info.display_name} - åˆ©ç”¨å¯èƒ½")
                if result.available_models:
                    models_preview = ", ".join(result.available_models[:2])
                    if len(result.available_models) > 2:
                        models_preview += f" ãªã©{len(result.available_models)}å€‹"
                    self.console.print(f"  [dim]ãƒ¢ãƒ‡ãƒ«: {models_preview}[/dim]")
            else:
                self.console.print(f"[red]âœ—[/red] {provider_info.display_name} - åˆ©ç”¨ä¸å¯")
                if result.error_message:
                    self.console.print(f"  [red]{result.error_message}[/red]")
                if result.warning_message:
                    self.console.print(f"  [yellow]{result.warning_message}[/yellow]")

        self.console.print()

    def _select_providers_and_models(self) -> None:
        """ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
        self.console.print("[bold blue]ğŸ¯ AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ[/bold blue]\n")

        # åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
        available_providers = [name for name, result in self.validation_results.items() if result.is_valid]

        if not available_providers:
            self.console.print("[red]åˆ©ç”¨å¯èƒ½ãªAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚[/red]")
            self.console.print("[yellow]APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚[/yellow]")
            return

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®é¸æŠ
        self.console.print("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")

        provider_choices = []
        provider_display = {}

        for provider_name in available_providers:
            provider_info = SUPPORTED_PROVIDERS[provider_name]
            choice_key = str(len(provider_choices) + 1)
            provider_choices.append(choice_key)
            provider_display[choice_key] = provider_name

            self.console.print(f"  {choice_key}. {provider_info.display_name}")

            # æ¨å¥¨ãƒãƒ¼ã‚¯ã‚’è¡¨ç¤º
            if provider_name == "openai":
                self.console.print("     [dim]ï¼ˆæ¨å¥¨: é«˜å“è³ªã§å®‰å®šï¼‰[/dim]")
            elif provider_name == "anthropic":
                self.console.print("     [dim]ï¼ˆé«˜å“è³ªã€é•·æ–‡å¯¾å¿œï¼‰[/dim]")
            elif provider_name == "local":
                self.console.print("     [dim]ï¼ˆç„¡æ–™ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆï¼‰[/dim]")

        default_choice = "1" if "1" in provider_choices else provider_choices[0]
        selected_choice = Prompt.ask(
            "\n[bold green]é¸æŠã—ã¦ãã ã•ã„[/bold green]", choices=provider_choices, default=default_choice
        )

        default_provider = provider_display[selected_choice]
        self.selected_providers = [default_provider]

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
        self._select_model_for_provider(default_provider, is_default=True)

        # è¿½åŠ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®é¸æŠ
        remaining_providers = [p for p in available_providers if p != default_provider]

        if remaining_providers and Confirm.ask("\n[bold blue]ä»–ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚‚è¨­å®šã—ã¾ã™ã‹ï¼Ÿ[/bold blue]"):
            for provider_name in remaining_providers:
                provider_info = SUPPORTED_PROVIDERS[provider_name]
                if Confirm.ask(f"{provider_info.display_name} ã‚’è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ"):
                    self.selected_providers.append(provider_name)
                    self._select_model_for_provider(provider_name)

    def _select_model_for_provider(self, provider_name: str, is_default: bool = False) -> None:
        """ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
        provider_info = SUPPORTED_PROVIDERS[provider_name]
        result = self.validation_results[provider_name]

        available_models = result.available_models if result.available_models else provider_info.available_models

        if len(available_models) <= 1:
            # ãƒ¢ãƒ‡ãƒ«ãŒ1ã¤ã—ã‹ãªã„å ´åˆã¯è‡ªå‹•é¸æŠ
            selected_model = available_models[0] if available_models else provider_info.default_model
            self.selected_models[provider_name] = selected_model

            prefix = "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ" if is_default else ""
            self.console.print(f"[dim]{prefix}ãƒ¢ãƒ‡ãƒ«: {selected_model}[/dim]")
            return

        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯é¸æŠ
        prefix = "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ" if is_default else provider_info.display_name
        self.console.print(f"\n{prefix}ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")

        model_choices = []
        model_display = {}

        for i, model in enumerate(available_models, 1):
            choice_key = str(i)
            model_choices.append(choice_key)
            model_display[choice_key] = model

            self.console.print(f"  {choice_key}. {model}")

            # æ¨å¥¨ãƒãƒ¼ã‚¯ã‚’è¡¨ç¤º
            if model == provider_info.default_model:
                self.console.print("     [dim]ï¼ˆæ¨å¥¨ï¼‰[/dim]")
            elif "mini" in model.lower() or "haiku" in model.lower():
                self.console.print("     [dim]ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰[/dim]")
            elif "4o" in model or "opus" in model.lower():
                self.console.print("     [dim]ï¼ˆé«˜æ€§èƒ½ï¼‰[/dim]")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠã‚’æ±ºå®š
        default_choice = "1"
        for choice, model in model_display.items():
            if model == provider_info.default_model:
                default_choice = choice
                break

        selected_choice = Prompt.ask(
            "[bold green]é¸æŠã—ã¦ãã ã•ã„[/bold green]", choices=model_choices, default=default_choice
        )

        selected_model = model_display[selected_choice]
        self.selected_models[provider_name] = selected_model

    def _configure_additional_settings(self) -> dict[str, Any]:
        """è¿½åŠ è¨­å®šã‚’è¡Œã†"""
        self.console.print("\n[bold blue]âš™ï¸ è¿½åŠ è¨­å®š[/bold blue]\n")

        config = {}

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
        cache_enabled = Confirm.ask("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã‹ï¼Ÿ", default=True)
        config["cache_enabled"] = cache_enabled

        if cache_enabled:
            cache_ttl = Prompt.ask("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ï¼ˆæ™‚é–“ï¼‰", default="24")
            try:
                config["cache_ttl_hours"] = int(cache_ttl)
            except ValueError:
                config["cache_ttl_hours"] = 24

        # ã‚³ã‚¹ãƒˆåˆ¶é™è¨­å®š
        if Confirm.ask("æœˆé–“ã‚³ã‚¹ãƒˆåˆ¶é™ã‚’è¨­å®šã—ã¾ã™ã‹ï¼Ÿ", default=True):
            monthly_limit = Prompt.ask("æœˆé–“ã‚³ã‚¹ãƒˆåˆ¶é™ï¼ˆUSDï¼‰", default="50.0")
            try:
                config["monthly_usd"] = float(monthly_limit)
            except ValueError:
                config["monthly_usd"] = 50.0

            per_request_limit = Prompt.ask("1å›ã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆåˆ¶é™ï¼ˆUSDï¼‰", default="1.0")
            try:
                config["per_request_usd"] = float(per_request_limit)
            except ValueError:
                config["per_request_usd"] = 1.0

        return config

    def _build_configuration(self, additional_config: dict[str, Any]) -> dict[str, Any]:
        """è¨­å®šã‚’æ§‹ç¯‰"""
        if not self.selected_providers:
            return {}

        default_provider = self.selected_providers[0]

        config = {
            "ai": {
                "default_provider": default_provider,
                "cache_enabled": additional_config.get("cache_enabled", True),
                "cache_ttl_hours": additional_config.get("cache_ttl_hours", 24),
                "providers": {},
                "cost_limits": {
                    "monthly_usd": additional_config.get("monthly_usd", 50.0),
                    "per_request_usd": additional_config.get("per_request_usd", 1.0),
                },
            }
        }

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’è¿½åŠ 
        for provider_name in self.selected_providers:
            provider_info = SUPPORTED_PROVIDERS[provider_name]
            result = self.validation_results[provider_name]

            selected_model = self.selected_models.get(provider_name, provider_info.default_model)
            available_models = result.available_models if result.available_models else provider_info.available_models

            provider_config = {
                "default_model": selected_model,
                "available_models": available_models,
                "timeout_seconds": 30,
                "max_retries": 3,
            }

            # ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å ´åˆã¯è¿½åŠ è¨­å®š
            if provider_name == "local":
                # WSLç’°å¢ƒã‚’æ¤œå‡ºã—ã¦é©åˆ‡ãªURLã‚’è¨­å®š
                default_url = "auto"  # è‡ªå‹•æ¤œå‡ºã‚’ç¤ºã™ç‰¹æ®Šå€¤
                provider_config["base_url"] = os.getenv("OLLAMA_BASE_URL", default_url)
                provider_config["timeout_seconds"] = 60

            config["ai"]["providers"][provider_name] = provider_config

        return config

    def _show_configuration_summary(self, config: dict[str, Any]) -> None:
        """è¨­å®šã®æ¦‚è¦ã‚’è¡¨ç¤º"""
        if not config:
            return

        self.console.print("\n[bold blue]ğŸ“‹ è¨­å®šæ¦‚è¦[/bold blue]\n")

        ai_config = config.get("ai", {})

        # åŸºæœ¬è¨­å®š
        table = Table(show_header=False, box=None)
        table.add_column("é …ç›®", style="cyan", width=20)
        table.add_column("å€¤", style="white")

        table.add_row("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", ai_config.get("default_provider", "æœªè¨­å®š"))
        table.add_row("ã‚­ãƒ£ãƒƒã‚·ãƒ¥", "æœ‰åŠ¹" if ai_config.get("cache_enabled") else "ç„¡åŠ¹")
        table.add_row("ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™", f"{ai_config.get('cache_ttl_hours', 24)}æ™‚é–“")

        cost_limits = ai_config.get("cost_limits", {})
        table.add_row("æœˆé–“ã‚³ã‚¹ãƒˆåˆ¶é™", f"${cost_limits.get('monthly_usd', 50.0)}")
        table.add_row("1å›ã‚ãŸã‚Šåˆ¶é™", f"${cost_limits.get('per_request_usd', 1.0)}")

        self.console.print(table)

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
        providers_config = ai_config.get("providers", {})
        if providers_config:
            self.console.print("\n[bold]è¨­å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼:[/bold]")
            for provider_name, provider_config in providers_config.items():
                provider_info = SUPPORTED_PROVIDERS[provider_name]
                self.console.print(f"â€¢ {provider_info.display_name}")
                self.console.print(f"  [dim]ãƒ¢ãƒ‡ãƒ«: {provider_config.get('default_model')}[/dim]")
                available_count = len(provider_config.get("available_models", []))
                self.console.print(f"  [dim]åˆ©ç”¨å¯èƒ½: {available_count}å€‹ã®ãƒ¢ãƒ‡ãƒ«[/dim]")

    def generate_toml_content(self, config: dict[str, Any]) -> str:
        """TOMLå½¢å¼ã®è¨­å®šå†…å®¹ã‚’ç”Ÿæˆ"""
        if not config:
            return ""

        lines = [
            "# ci-helper configuration file",
            "# Generated by interactive setup",
            "",
            "[ci-helper]",
            'log_dir = ".ci-helper/logs"',
            'cache_dir = ".ci-helper/cache"',
            'reports_dir = ".ci-helper/reports"',
            "context_lines = 3",
            "max_log_size_mb = 100",
            "max_cache_size_mb = 500",
            'act_image = "ghcr.io/catthehacker/ubuntu:full-24.04"',
            "timeout_seconds = 1800",
            "verbose = false",
            "save_logs = true",
            "",
            '# æ³¨æ„: base_urlã«"auto"ã‚’è¨­å®šã™ã‚‹ã¨ã€WSLç’°å¢ƒã§ã¯è‡ªå‹•çš„ã«Windowsãƒ›ã‚¹ãƒˆã®IPã‚’æ¤œå‡ºã—ã¾ã™',
            "",
        ]

        ai_config = config.get("ai", {})

        # AIåŸºæœ¬è¨­å®š
        lines.extend(
            [
                "[ai]",
                f'default_provider = "{ai_config.get("default_provider", "openai")}"',
                f"cache_enabled = {str(ai_config.get('cache_enabled', True)).lower()}",
                f"cache_ttl_hours = {ai_config.get('cache_ttl_hours', 24)}",
                "",
            ]
        )

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
        providers_config = ai_config.get("providers", {})
        for provider_name, provider_config in providers_config.items():
            lines.extend(
                [
                    f"[ai.providers.{provider_name}]",
                    f'default_model = "{provider_config.get("default_model")}"',
                ]
            )

            # available_models ã‚’é…åˆ—ã¨ã—ã¦å‡ºåŠ›
            available_models = provider_config.get("available_models", [])
            if available_models:
                models_str = '", "'.join(available_models)
                lines.append(f'available_models = ["{models_str}"]')

            lines.extend(
                [
                    f"timeout_seconds = {provider_config.get('timeout_seconds', 30)}",
                    f"max_retries = {provider_config.get('max_retries', 3)}",
                ]
            )

            # ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å ´åˆã¯ base_url ã‚’è¿½åŠ 
            if provider_name == "local" and "base_url" in provider_config:
                base_url = provider_config["base_url"]
                lines.append(f'base_url = "{base_url}"  # "auto" ã§è‡ªå‹•æ¤œå‡ºã€ã¾ãŸã¯ç›´æ¥URLã‚’æŒ‡å®š')

            lines.append("")

        # ã‚³ã‚¹ãƒˆåˆ¶é™è¨­å®š
        cost_limits = ai_config.get("cost_limits", {})
        if cost_limits:
            lines.extend(
                [
                    "[ai.cost_limits]",
                    f"monthly_usd = {cost_limits.get('monthly_usd', 50.0)}",
                    f"per_request_usd = {cost_limits.get('per_request_usd', 1.0)}",
                    "",
                ]
            )

        return "\n".join(lines)
