"""
analyze ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£…

AIåˆ†ææ©Ÿèƒ½ã‚’æä¾›ã—ã€CI/CDã®å¤±æ•—ãƒ­ã‚°ã‚’åˆ†æã—ã¦æ ¹æœ¬åŸå› ã®ç‰¹å®šã¨ä¿®æ­£ææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚
"""

from __future__ import annotations

import asyncio
import sys
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

import click
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

if TYPE_CHECKING:
    from ..ai.models import AnalysisResult

from ..ai.exceptions import (
    APIKeyError,
    ConfigurationError,
    NetworkError,
    ProviderError,
    RateLimitError,
    TokenLimitError,
)
from ..ai.integration import AIIntegration
from ..ai.models import AnalyzeOptions
from ..core.error_handler import ErrorHandler
from ..core.exceptions import CIHelperError
from ..core.log_manager import LogManager
from ..utils.config import Config

console = Console()


class AnalysisErrorContext:
    """åˆ†æã‚¨ãƒ©ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†"""

    def __init__(self, console: Console, operation_name: str, verbose: bool = False):
        self.console = console
        self.operation_name = operation_name
        self.verbose = verbose
        self.start_time = datetime.now()
        self.error_count = 0

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            self.error_count += 1
            duration = (datetime.now() - self.start_time).total_seconds()

            # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã‚’ãƒ­ã‚°ã«è¨˜éŒ²
            import logging

            logger = logging.getLogger(__name__)
            logger.error("æ“ä½œ '%s' ãŒ %.2fç§’å¾Œã«ã‚¨ãƒ©ãƒ¼ã§çµ‚äº†: %s", self.operation_name, duration, exc_val)

        return False  # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã‚‹

    def log_progress(self, message: str):
        """é€²æ—ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        elapsed = (datetime.now() - self.start_time).total_seconds()
        if self.verbose:
            self.console.print(f"[dim][{elapsed:.1f}s] {message}[/dim]")


@click.command()
@click.option(
    "--log",
    "log_file",
    type=click.Path(exists=True, path_type=Path),
    help="åˆ†æã™ã‚‹ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯æœ€æ–°ã®ãƒ­ã‚°ã‚’ä½¿ç”¨ï¼‰",
)
@click.option(
    "--provider",
    type=click.Choice(["openai", "anthropic", "local"], case_sensitive=False),
    help="ä½¿ç”¨ã™ã‚‹AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä¸Šæ›¸ãï¼‰",
)
@click.option(
    "--model",
    help="ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹: gpt-4o, claude-3-sonnetï¼‰",
)
@click.option(
    "--prompt",
    "custom_prompt",
    help="ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ",
)
@click.option(
    "--fix",
    is_flag=True,
    help="ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆã—ã€é©ç”¨ã®ç¢ºèªã‚’è¡Œã†",
)
@click.option(
    "--interactive",
    "-i",
    is_flag=True,
    help="å¯¾è©±çš„ãªAIãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹",
)
@click.option(
    "--streaming/--no-streaming",
    default=None,
    help="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æœ‰åŠ¹/ç„¡åŠ¹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä¸Šæ›¸ãï¼‰",
)
@click.option(
    "--cache/--no-cache",
    default=True,
    help="AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ï¼‰",
)
@click.option(
    "--stats",
    is_flag=True,
    help="AIä½¿ç”¨çµ±è¨ˆã‚’è¡¨ç¤º",
)
@click.option(
    "--format",
    "output_format",
    type=click.Choice(["markdown", "json", "table"], case_sensitive=False),
    default="markdown",
    help="å‡ºåŠ›å½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: markdownï¼‰",
)
@click.option(
    "--verbose",
    "-v",
    is_flag=True,
    help="è©³ç´°ãªå®Ÿè¡Œæƒ…å ±ã‚’è¡¨ç¤º",
)
@click.option(
    "--retry",
    "retry_operation_id",
    help="å¤±æ•—ã—ãŸæ“ä½œã‚’ãƒªãƒˆãƒ©ã‚¤ï¼ˆæ“ä½œIDã‚’æŒ‡å®šï¼‰",
)
@click.pass_context
def analyze(
    ctx: click.Context,
    log_file: Path | None,
    provider: str | None,
    model: str | None,
    custom_prompt: str | None,
    fix: bool,
    interactive: bool,
    streaming: bool | None,
    cache: bool,
    stats: bool,
    output_format: str,
    verbose: bool,
    retry_operation_id: str | None,
) -> None:
    """CI/CDã®å¤±æ•—ãƒ­ã‚°ã‚’AIã§åˆ†æ

    æŒ‡å®šã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯æœ€æ–°ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã‚’AIãŒåˆ†æã—ã€
    æ ¹æœ¬åŸå› ã®ç‰¹å®šã¨ä¿®æ­£ææ¡ˆã‚’æä¾›ã—ã¾ã™ã€‚

    \b
    ä½¿ç”¨ä¾‹:
      ci-run analyze                           # æœ€æ–°ã®ãƒ­ã‚°ã‚’åˆ†æ
      ci-run analyze --log path/to/log         # ç‰¹å®šã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
      ci-run analyze --provider openai         # OpenAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨
      ci-run analyze --model gpt-4o            # ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
      ci-run analyze --fix                     # ä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆ
      ci-run analyze --interactive             # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§åˆ†æ
      ci-run analyze --stats                   # ä½¿ç”¨çµ±è¨ˆã‚’è¡¨ç¤º
    """
    try:
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨­å®šã‚’å–å¾—
        config: Config = ctx.obj["config"]
        console: Console = ctx.obj["console"]

        # çµ±è¨ˆè¡¨ç¤ºã®ã¿ã®å ´åˆ
        if stats:
            _display_stats(config, console)
            return

        # ç’°å¢ƒã®äº‹å‰æ¤œè¨¼
        validation_result = _validate_analysis_environment(config, console)
        if not validation_result:
            console.print("\n[red]ç’°å¢ƒè¨­å®šã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚[/red]")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ææ¡ˆ
            _suggest_fallback_options(console, log_file)

            # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æä¾›
            console.print("\n[dim]è©³ç´°ãªãƒ˜ãƒ«ãƒ—: ci-run analyze --help[/dim]")
            sys.exit(1)

        # AIçµ±åˆã®åˆæœŸåŒ–
        ai_integration = AIIntegration(config)

        # ãƒªãƒˆãƒ©ã‚¤æ“ä½œã®å ´åˆ
        if retry_operation_id:
            asyncio.run(_handle_retry_operation(ai_integration, retry_operation_id, console))
            return

        # éåŒæœŸå®Ÿè¡Œ
        asyncio.run(
            _run_analysis(
                ai_integration=ai_integration,
                log_file=log_file,
                provider=provider,
                model=model,
                custom_prompt=custom_prompt,
                fix=fix,
                interactive=interactive,
                streaming=streaming,
                use_cache=cache,
                output_format=output_format,
                verbose=verbose,
                console=console,
            )
        )

    except KeyboardInterrupt:
        console.print("\n[yellow]åˆ†æãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚[/yellow]")
        console.print("[dim]éƒ¨åˆ†çš„ãªçµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚[/dim]")
        sys.exit(130)
    except CIHelperError as e:
        # æ—¥æœ¬èªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½¿ç”¨
        japanese_handler = JapaneseErrorHandler()
        error_info = japanese_handler.handle_error(e, "analyze ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œä¸­")

        console.print(f"[red]âŒ {error_info['message']}[/red]")

        if error_info["suggestion"]:
            console.print(f"[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue] {error_info['suggestion']}")

        if error_info["recovery_steps"]:
            console.print("[blue]ğŸ“‹ å¾©æ—§æ‰‹é †:[/blue]")
            for i, step in enumerate(error_info["recovery_steps"], 1):
                console.print(f"  {i}. {step}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ææ¡ˆ
        _suggest_fallback_options(console, log_file)

        ErrorHandler.handle_error(e, verbose)
        sys.exit(1)
    except Exception as e:
        # æ—¥æœ¬èªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½¿ç”¨
        japanese_handler = JapaneseErrorHandler()
        error_info = japanese_handler.handle_error(e, "AIåˆ†æå®Ÿè¡Œä¸­")

        console.print(f"[red]âŒ {error_info['message']}[/red]")

        # AIå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆè©³ç´°ï¼‰
        _handle_analysis_error(e, console, verbose)

        # è‡ªå‹•å¾©æ—§ã®ææ¡ˆã¨å®Ÿè¡Œ
        recovery_choice = _offer_interactive_recovery(console)

        if recovery_choice == "auto":
            console.print("\n[blue]ğŸ”„ è‡ªå‹•å¾©æ—§ã‚’æº–å‚™ä¸­...[/blue]")
            console.print("[yellow]è‡ªå‹•å¾©æ—§ã¯æ¬¡å›ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã«åˆ©ç”¨å¯èƒ½ã§ã™[/yellow]")
            console.print("[cyan]ci-run analyze --retry auto[/cyan] ã§è‡ªå‹•å¾©æ—§ã‚’è©¦è¡Œã§ãã¾ã™")

            # å¾©æ—§æƒ…å ±ã‚’ä¿å­˜ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
            try:
                recovery_info = {
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "timestamp": datetime.now().isoformat(),
                    "options": {
                        "provider": provider,
                        "model": model,
                        "custom_prompt": custom_prompt,
                        "fix": fix,
                        "interactive": interactive,
                        "streaming": streaming,
                        "cache": cache,
                        "output_format": output_format,
                        "verbose": verbose,
                    },
                    "log_file": str(log_file) if log_file else None,
                }

                # å¾©æ—§æƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                recovery_dir = config.get_path("cache_dir") / "recovery"
                recovery_dir.mkdir(parents=True, exist_ok=True)
                recovery_file = recovery_dir / "last_error.json"

                import json

                with recovery_file.open("w", encoding="utf-8") as f:
                    json.dump(recovery_info, f, ensure_ascii=False, indent=2)

                console.print(f"[dim]å¾©æ—§æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {recovery_file}[/dim]")

            except Exception as save_error:
                console.print(f"[yellow]âš ï¸  å¾©æ—§æƒ…å ±ã®ä¿å­˜ã«å¤±æ•—: {save_error}[/yellow]")

        elif recovery_choice == "manual":
            # æ‰‹å‹•å¯¾å‡¦ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’è¡¨ç¤º
            _suggest_fallback_options(console, log_file)

        # recovery_choice == "skip" ã®å ´åˆã¯ãã®ã¾ã¾çµ‚äº†

        # ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        ErrorHandler.handle_error(e, verbose)
        sys.exit(1)


async def _run_analysis(
    ai_integration: AIIntegration,
    log_file: Path | None,
    provider: str | None,
    model: str | None,
    custom_prompt: str | None,
    fix: bool,
    interactive: bool,
    streaming: bool | None,
    use_cache: bool,
    output_format: str,
    verbose: bool,
    console: Console,
) -> None:
    """AIåˆ†æã®å®Ÿè¡Œ

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        log_file: åˆ†æã™ã‚‹ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
        provider: AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
        model: AIãƒ¢ãƒ‡ãƒ«
        custom_prompt: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        fix: ä¿®æ­£ææ¡ˆãƒ•ãƒ©ã‚°
        interactive: å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°
        streaming: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ•ãƒ©ã‚°
        use_cache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ãƒ•ãƒ©ã‚°
        output_format: å‡ºåŠ›å½¢å¼
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    try:
        # AIçµ±åˆã®åˆæœŸåŒ–
        await ai_integration.initialize()

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ±ºå®š
        if log_file is None:
            log_file = _get_latest_log_file(ai_integration.config)

        if log_file is None:
            console.print("[red]åˆ†æã™ã‚‹ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚[/red]")
            console.print("ã¾ãš `ci-run test` ã‚’å®Ÿè¡Œã—ã¦ãƒ­ã‚°ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
            return

        # ãƒ­ã‚°å†…å®¹ã®èª­ã¿è¾¼ã¿
        log_content = _read_log_file(log_file)

        # åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰
        from ..ai.models import AnalyzeOptions

        options = AnalyzeOptions(
            provider=provider,
            model=model,
            custom_prompt=custom_prompt,
            streaming=streaming if streaming is not None else True,
            use_cache=use_cache,
            generate_fixes=fix,
            output_format=output_format,
            force_ai_analysis=True,  # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æŒ‡å®šæ™‚ã¯AIåˆ†æã‚’å¼·åˆ¶
        )

        # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
        if interactive:
            await _run_interactive_mode(ai_integration, log_content, options, console)
            return

        # é€šå¸¸ã®åˆ†æãƒ¢ãƒ¼ãƒ‰
        await _run_standard_analysis(ai_integration, log_content, options, verbose, console)

    except Exception as e:
        # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        console.print("\n[red]åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/red]")
        _handle_analysis_error(e, console, verbose)

        # éƒ¨åˆ†çš„ãªçµæœã®ä¿å­˜ã‚’è©¦è¡Œ
        try:
            await _save_partial_analysis_state(ai_integration, log_content, options, e)
            console.print("[dim]éƒ¨åˆ†çš„ãªçŠ¶æ…‹ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚å¾Œã§ãƒªãƒˆãƒ©ã‚¤ã§ãã¾ã™ã€‚[/dim]")
        except Exception:
            pass  # éƒ¨åˆ†ä¿å­˜ã®å¤±æ•—ã¯ç„¡è¦–

        # è‡ªå‹•å¾©æ—§ã‚’ææ¡ˆï¼ˆéå¯¾è©±çš„ï¼‰
        console.print("\n[blue]ğŸ’¡ è‡ªå‹•å¾©æ—§ã‚ªãƒ—ã‚·ãƒ§ãƒ³:[/blue]")
        console.print("  ã‚³ãƒãƒ³ãƒ‰ã‚’å†å®Ÿè¡Œã™ã‚‹ã¨è‡ªå‹•å¾©æ—§ã‚’è©¦è¡Œã§ãã¾ã™")
        console.print("  [cyan]ci-run analyze --retry auto[/cyan]")

        raise
    finally:
        # ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            for provider in ai_integration.providers.values():
                if hasattr(provider, "cleanup"):
                    await provider.cleanup()
        except Exception:
            pass


async def _run_standard_analysis(
    ai_integration: AIIntegration,
    log_content: str,
    options: AnalyzeOptions,
    verbose: bool,
    console: Console,
) -> None:
    """æ¨™æº–åˆ†æãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        log_content: ãƒ­ã‚°å†…å®¹
        options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        # åˆ†æã‚¿ã‚¹ã‚¯ã®é–‹å§‹
        task = progress.add_task("AIåˆ†æã‚’å®Ÿè¡Œä¸­...", total=None)

        try:
            # AIåˆ†æã®å®Ÿè¡Œ
            result = await ai_integration.analyze_log(log_content, options)

            progress.update(task, description="åˆ†æå®Œäº†")
            progress.stop()

            # çµæœã®è¡¨ç¤º
            _display_analysis_result(result, options.output_format, console)

            # ä¿®æ­£ææ¡ˆã®å‡¦ç†
            if options.generate_fixes and result.fix_suggestions:
                _display_fix_suggestions(result, console)

                # ä¿®æ­£é©ç”¨ã®ç¢ºèª
                # ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚„CIç’°å¢ƒã§ã¯é©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
                fixes_applied = await _handle_fix_application(ai_integration, result, console)

                # ä¿®æ­£ãŒæ‹’å¦ã•ã‚ŒãŸå ´åˆã¯çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã§çµ‚äº†
                if not fixes_applied:
                    console.print("\n[yellow]ä¿®æ­£ãŒé©ç”¨ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚[/yellow]")
                    sys.exit(1)

        except Exception as e:
            progress.stop()
            # AIå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            _handle_analysis_error(e, console, False)
            raise


async def _run_interactive_mode(
    ai_integration: AIIntegration,
    log_content: str,
    options: AnalyzeOptions,
    console: Console,
) -> None:
    """å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        log_content: ãƒ­ã‚°å†…å®¹
        options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    console.print(Panel.fit("ğŸ¤– å¯¾è©±çš„AIãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™", style="blue"))
    console.print("çµ‚äº†ã™ã‚‹ã«ã¯ '/exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    console.print("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰ã¯ '/help' ã§ç¢ºèªã§ãã¾ã™ã€‚")
    console.print()

    # å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹
    session = await ai_integration.start_interactive_session(log_content, options)

    try:
        while session.is_active:
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å–å¾—
                user_input = console.input("[bold blue]> [/bold blue]")

                if not user_input.strip():
                    continue

                # AIå¿œç­”ã®å‡¦ç†
                async for response_chunk in ai_integration.process_interactive_input(session.session_id, user_input):
                    console.print(response_chunk, end="")

                console.print()  # æ”¹è¡Œ

            except Exception as e:
                # å€‹åˆ¥ã®å¯¾è©±ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ç¶™ç¶šï¼‰
                console.print(f"\n[red]å¯¾è©±ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/red] {e}")

                # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
                from ..ai.exceptions import NetworkError, RateLimitError, TokenLimitError

                if isinstance(e, RateLimitError):
                    retry_time = e.retry_after or 60
                    console.print(f"[yellow]â±ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{retry_time}ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚[/yellow]")

                    # çŸ­æ™‚é–“ã®å ´åˆã¯è‡ªå‹•å¾…æ©Ÿã‚’ææ¡ˆ
                    if retry_time <= 120:  # 2åˆ†ä»¥å†…
                        console.print("[blue]ğŸ’¡ è‡ªå‹•å¾…æ©Ÿã—ã¾ã™ã‹ï¼Ÿ (y/n)[/blue]")
                        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹

                elif isinstance(e, NetworkError):
                    console.print("[yellow]ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚[/yellow]")
                    console.print("[blue]ğŸ’¡ å¾©æ—§æ‰‹é †:[/blue]")
                    console.print("  1. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª")
                    console.print("  2. ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç¢ºèª")
                    console.print("  3. '/retry' ã§å†è©¦è¡Œ")

                elif isinstance(e, TokenLimitError):
                    console.print("[yellow]ğŸ“Š å…¥åŠ›ãŒé•·ã™ãã¾ã™ã€‚ã‚ˆã‚ŠçŸ­ã„è³ªå•ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚[/yellow]")
                    console.print("[blue]ğŸ’¡ å¯¾å‡¦æ³•:[/blue]")
                    console.print("  â€¢ è³ªå•ã‚’çŸ­ç¸®ã™ã‚‹")
                    console.print("  â€¢ '/summarize' ã§è¦ç´„ã‚’ä¾é ¼")
                    console.print("  â€¢ '/model smaller' ã§å°ã•ãªãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´")

                else:
                    console.print("[yellow]âš ï¸  ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚[/yellow]")
                    console.print("[blue]ğŸ’¡ å¯¾å‡¦æ³•:[/blue]")
                    console.print("  â€¢ '/retry' ã§å†è©¦è¡Œ")
                    console.print("  â€¢ '/provider switch' ã§åˆ¥ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¤‰æ›´")
                    console.print("  â€¢ '/reset' ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ")

                # å¯¾è©±ç¶™ç¶šã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                console.print("\n[blue]ğŸ”„ å¯¾è©±ã‚ªãƒ—ã‚·ãƒ§ãƒ³:[/blue]")
                console.print("  [green]/retry[/green] - æœ€å¾Œã®è³ªå•ã‚’å†è©¦è¡Œ")
                console.print("  [yellow]/help[/yellow] - åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰ã‚’è¡¨ç¤º")
                console.print("  [red]/exit[/red] - å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†")

                # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆã®æ›´æ–°ï¼ˆå®Ÿè£…ã¯åˆ¥é€”ï¼‰
                console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}[/dim]")

    except KeyboardInterrupt:
        console.print("\n[yellow]å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚[/yellow]")
    except Exception as e:
        console.print(f"\n[red]å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/red] {e}")
        _handle_analysis_error(e, console, False)
    finally:
        try:
            await ai_integration.close_interactive_session(session.session_id)
        except Exception:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆæ—¢ã«çµ‚äº†ã—ã¦ã„ã‚‹å¯èƒ½æ€§ï¼‰
            pass


def _display_fix_suggestions(result: AnalysisResult, console: Console) -> None:
    """ä¿®æ­£ææ¡ˆã®è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    console.print("\n[bold green]ä¿®æ­£ææ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:[/bold green]")

    for i, suggestion in enumerate(result.fix_suggestions, 1):
        console.print(f"\n[bold]ä¿®æ­£æ¡ˆ {i}:[/bold]")
        console.print(f"ã‚¿ã‚¤ãƒˆãƒ«: {suggestion.title}")
        console.print(f"èª¬æ˜: {suggestion.description}")

        # ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¡¨ç¤º
        if suggestion.code_changes:
            files = {change.file_path for change in suggestion.code_changes}
            console.print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(files)}")

        console.print(f"å„ªå…ˆåº¦: {suggestion.priority.value}")
        console.print(f"æ¨å®šä½œæ¥­æ™‚é–“: {suggestion.estimated_effort}")
        console.print(f"ä¿¡é ¼åº¦: {suggestion.confidence:.1%}")


async def _handle_fix_application(
    ai_integration: AIIntegration,
    result: AnalysisResult,
    console: Console,
) -> bool:
    """ä¿®æ­£ææ¡ˆã®é©ç”¨å‡¦ç†

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        result: åˆ†æçµæœ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«

    Returns:
        bool: å°‘ãªãã¨ã‚‚1ã¤ã®ä¿®æ­£ãŒé©ç”¨ã•ã‚ŒãŸå ´åˆTrueã€ãã†ã§ãªã‘ã‚Œã°False
    """
    console.print("\n[bold yellow]ä¿®æ­£ææ¡ˆã‚’é©ç”¨ã—ã¾ã™ã‹ï¼Ÿ[/bold yellow]")

    applied_count = 0
    user_rejected = False

    for i, suggestion in enumerate(result.fix_suggestions, 1):
        try:
            # ä¿®æ­£ã®é©ç”¨ç¢ºèª
            if click.confirm(f"ä¿®æ­£æ¡ˆ {i} ({suggestion.title}) ã‚’é©ç”¨ã—ã¾ã™ã‹ï¼Ÿ"):
                try:
                    await ai_integration.apply_fix(suggestion)
                    console.print(f"[green]ä¿®æ­£æ¡ˆ {i} ã‚’é©ç”¨ã—ã¾ã—ãŸã€‚[/green]")
                    applied_count += 1
                except Exception as e:
                    console.print(f"[red]ä¿®æ­£æ¡ˆ {i} ã®é©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ:[/red] {e}")

                    # ä¿®æ­£å¤±æ•—ã®è©³ç´°ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
                    console.print("[blue]ğŸ’¡ ä¿®æ­£å¤±æ•—ã®å¯¾å‡¦æ³•:[/blue]")
                    console.print("  â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                    console.print("  â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ãŒä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèª")
                    console.print("  â€¢ æ‰‹å‹•ã§ä¿®æ­£ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™")
                    console.print("  â€¢ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ: [cyan]ci-run analyze --restore-backup[/cyan]")

                    # ç¶šè¡Œã™ã‚‹ã‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
                    if i < len(result.fix_suggestions):
                        try:
                            continue_applying = click.confirm("ä»–ã®ä¿®æ­£æ¡ˆã®é©ç”¨ã‚’ç¶šã‘ã¾ã™ã‹ï¼Ÿ")
                            if not continue_applying:
                                console.print("[yellow]ä¿®æ­£æ¡ˆã®é©ç”¨ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚[/yellow]")
                                user_rejected = True
                                break
                        except (EOFError, KeyboardInterrupt, click.exceptions.Abort):
                            console.print("[yellow]ä¿®æ­£æ¡ˆã®é©ç”¨ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚[/yellow]")
                            break
            else:
                console.print(f"[yellow]ä¿®æ­£æ¡ˆ {i} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚[/yellow]")
                user_rejected = True
        except (EOFError, KeyboardInterrupt, click.exceptions.Abort):
            # å…¥åŠ›ãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼ˆãƒ†ã‚¹ãƒˆç’°å¢ƒãªã©ï¼‰ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ãŸå ´åˆ
            console.print("\n[dim]å¯¾è©±çš„å…¥åŠ›ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä¿®æ­£ææ¡ˆã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã—ãŸã€‚[/dim]")
            # å…¥åŠ›ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯æ‹’å¦ã¨ã¯è¦‹ãªã•ãªã„
            break

    # ä¿®æ­£ãŒé©ç”¨ã•ã‚ŒãŸã‹ã€ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«æ‹’å¦ã—ã¦ã„ãªã„å ´åˆã¯æˆåŠŸ
    return applied_count > 0 or not user_rejected


def _display_analysis_result(result: AnalysisResult, output_format: str, console: Console) -> None:
    """åˆ†æçµæœã®è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        output_format: å‡ºåŠ›å½¢å¼
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    # æ‹¡å¼µãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã‚’ä½¿ç”¨
    formatter = EnhancedAnalysisFormatter(console, language="ja")

    if output_format in ["enhanced", "markdown", "json", "table"]:
        formatter.format_analysis_result(result, output_format)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®è¡¨ç¤ºæ–¹å¼
        if output_format == "json":
            import json
            from dataclasses import asdict

            console.print(json.dumps(asdict(result), indent=2, ensure_ascii=False, default=str))
        elif output_format == "table":
            _display_result_as_table(result, console)
        else:  # markdown
            _display_result_as_markdown(result, console)


def _display_result_as_markdown(result: AnalysisResult, console: Console) -> None:
    """åˆ†æçµæœã‚’Markdownå½¢å¼ã§è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’æœ€åˆã«è¡¨ç¤º
    _display_fallback_info(result, console)

    console.print(Panel.fit("ğŸ” AIåˆ†æçµæœ", style="blue"))
    console.print()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜çµæœã‚’è¡¨ç¤ºï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    _display_pattern_recognition_results(result, console)

    # è¦ç´„
    if result.summary:
        console.print("[bold]è¦ç´„:[/bold]")
        console.print(result.summary)
        console.print()

    # æ ¹æœ¬åŸå› 
    if result.root_causes:
        console.print("[bold]æ ¹æœ¬åŸå› :[/bold]")
        for i, cause in enumerate(result.root_causes, 1):
            console.print(f"{i}. {cause.description}")
            if cause.file_path:
                console.print(f"   ãƒ•ã‚¡ã‚¤ãƒ«: {cause.file_path}")
            if cause.line_number:
                console.print(f"   è¡Œç•ªå·: {cause.line_number}")
            # ä¿¡é ¼åº¦ã‚’è¡¨ç¤ºï¼ˆæ–°æ©Ÿèƒ½ï¼‰
            if hasattr(cause, "confidence") and cause.confidence > 0:
                console.print(f"   ä¿¡é ¼åº¦: {cause.confidence:.1%}")
        console.print()

    # ä¿®æ­£ææ¡ˆï¼ˆè©³ç´°è¡¨ç¤ºã«æ‹¡å¼µï¼‰
    if result.fix_suggestions:
        _display_detailed_fix_suggestions(result.fix_suggestions, console)

    # é–¢é€£ã‚¨ãƒ©ãƒ¼
    if result.related_errors:
        console.print("[bold]é–¢é€£ã‚¨ãƒ©ãƒ¼:[/bold]")
        for error in result.related_errors[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
            console.print(f"- {error}")
        if len(result.related_errors) > 5:
            console.print(f"... ä»– {len(result.related_errors) - 5} å€‹")
        console.print()

    # çµ±è¨ˆæƒ…å ±
    console.print("[dim]çµ±è¨ˆæƒ…å ±:[/dim]")
    console.print(f"[dim]ä¿¡é ¼åº¦: {result.confidence_score:.1%}[/dim]")
    console.print(f"[dim]åˆ†ææ™‚é–“: {result.analysis_time:.2f}ç§’[/dim]")
    console.print(f"[dim]ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {result.provider}[/dim]")
    console.print(f"[dim]ãƒ¢ãƒ‡ãƒ«: {result.model}[/dim]")
    if result.tokens_used:
        console.print(f"[dim]ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {result.tokens_used.total_tokens:,}[/dim]")
        console.print(f"[dim]æ¨å®šã‚³ã‚¹ãƒˆ: ${result.tokens_used.estimated_cost:.4f}[/dim]")
    if result.cache_hit:
        console.print("[dim]ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: ã¯ã„[/dim]")


def _display_result_as_table(result: AnalysisResult, console: Console) -> None:
    """åˆ†æçµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    from rich.table import Table

    table = Table(title="AIåˆ†æçµæœ")
    table.add_column("é …ç›®", style="cyan")
    table.add_column("å†…å®¹", style="white")

    if result.summary:
        table.add_row("è¦ç´„", result.summary)
    if result.root_causes:
        root_causes_text = "\n".join(f"{i}. {cause.description}" for i, cause in enumerate(result.root_causes, 1))
        table.add_row("æ ¹æœ¬åŸå› ", root_causes_text)
    if result.fix_suggestions:
        suggestions_text = "\n".join(f"{i}. {fix.title}" for i, fix in enumerate(result.fix_suggestions, 1))
        table.add_row("ä¿®æ­£ææ¡ˆ", suggestions_text)

    console.print(table)


def _display_stats(config: Config, console: Console) -> None:
    """AIä½¿ç”¨çµ±è¨ˆã®è¡¨ç¤º

    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    try:
        from ..ai.cost_manager import CostManager

        storage_path = config.get_path("cache_dir") / "ai" / "usage.json"
        cost_manager = CostManager(storage_path, config.get_ai_cost_limits())
        stats = cost_manager.get_monthly_report(datetime.now().year, datetime.now().month)

        console.print(Panel.fit("ğŸ“Š AIä½¿ç”¨çµ±è¨ˆ", style="blue"))
        console.print()

        # æœˆé–“çµ±è¨ˆ
        if stats.get("stats"):
            monthly = stats["stats"]
            console.print("[bold]ä»Šæœˆã®ä½¿ç”¨é‡:[/bold]")
            console.print(f"ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {monthly.get('total_tokens', 0):,}")
            console.print(f"ç·ã‚³ã‚¹ãƒˆ: ${monthly.get('total_cost', 0):.4f}")
            console.print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {monthly.get('total_requests', 0)}")
            console.print(f"æˆåŠŸç‡: {monthly.get('success_rate', 0):.1%}")
            console.print()

        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥çµ±è¨ˆ
        if stats.get("provider_breakdown"):
            console.print("[bold]ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ä½¿ç”¨é‡:[/bold]")
            for provider, data in stats["provider_breakdown"].items():
                if isinstance(data, dict):
                    console.print(
                        f"{provider}: {data.get('total_tokens', 0):,} ãƒˆãƒ¼ã‚¯ãƒ³, ${data.get('total_cost', 0):.4f}"
                    )
                else:
                    console.print(f"{provider}: {data:,} å›ä½¿ç”¨")

    except Exception as e:
        console.print(f"[red]çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}[/red]")


def _get_latest_log_file(config: Config) -> Path | None:
    """æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—

    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Returns:
        æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
    """
    try:
        log_manager = LogManager(config)
        logs = log_manager.list_logs()
        if logs:
            log_dir = config.get_path("log_dir")
            log_filename = logs[0].get("log_file") or logs[0].get("file_path")
            if log_filename:
                return log_dir / log_filename
        return None
    except Exception:
        return None


def _read_log_file(log_file: Path) -> str:
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿

    Args:
        log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹

    Raises:
        CIHelperError: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        return log_file.read_text(encoding="utf-8")
    except Exception as e:
        raise CIHelperError(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e


async def _handle_retry_operation(ai_integration: AIIntegration, operation_id: str, console: Console) -> None:
    """å¤±æ•—ã—ãŸæ“ä½œã‚’ãƒªãƒˆãƒ©ã‚¤

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        operation_id: æ“ä½œID
        console: ã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    try:
        console.print(f"[blue]æ“ä½œ {operation_id} ã‚’ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã„ã¾ã™...[/blue]")

        # AIçµ±åˆã‚’åˆæœŸåŒ–
        await ai_integration.initialize()

        # ãƒªãƒˆãƒ©ã‚¤ã‚’å®Ÿè¡Œ
        result = await ai_integration.retry_failed_operation(operation_id)

        if result:
            console.print("[green]âœ“ ãƒªãƒˆãƒ©ã‚¤ãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
            _display_analysis_result(result, "markdown", console)
        else:
            console.print(f"[red]âœ— æ“ä½œ {operation_id} ã®ãƒªãƒˆãƒ©ã‚¤ã«å¤±æ•—ã—ã¾ã—ãŸ[/red]")
            console.print("[yellow]æ“ä½œIDãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ãƒªãƒˆãƒ©ã‚¤æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚[/yellow]")

    except Exception as e:
        console.print(f"[red]âœ— ãƒªãƒˆãƒ©ã‚¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}[/red]")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆã‚’è¡¨ç¤º
        suggestions = await ai_integration.get_fallback_suggestions(e)
        if suggestions:
            console.print("\n[yellow]ææ¡ˆ:[/yellow]")
            for i, suggestion in enumerate(suggestions, 1):
                console.print(f"  {i}. {suggestion}")


def _display_pattern_recognition_results(result: AnalysisResult, console: Console) -> None:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜çµæœã‚’è©³ç´°è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæƒ…å ±ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
    pattern_matches = getattr(result, "pattern_matches", None)
    if not pattern_matches:
        return

    from rich.table import Table

    console.print(Panel.fit("ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³", style="green"))
    console.print()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
    pattern_table = Table(title="ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜çµæœ", show_header=True, header_style="bold green")
    pattern_table.add_column("ãƒ‘ã‚¿ãƒ¼ãƒ³å", style="cyan", width=25)
    pattern_table.add_column("ã‚«ãƒ†ã‚´ãƒª", style="yellow", width=12)
    pattern_table.add_column("ä¿¡é ¼åº¦", style="green", width=10)
    pattern_table.add_column("ãƒãƒƒãƒç†ç”±", style="white", width=35)

    for match in pattern_matches:
        # ä¿¡é ¼åº¦ã‚’è‰²åˆ†ã‘
        confidence_color = "green" if match.confidence >= 0.8 else "yellow" if match.confidence >= 0.6 else "red"
        confidence_text = f"[{confidence_color}]{match.confidence:.1%}[/{confidence_color}]"

        # ãƒãƒƒãƒç†ç”±ã‚’æ§‹ç¯‰
        match_reasons = []
        if hasattr(match, "supporting_evidence") and match.supporting_evidence:
            match_reasons.extend(match.supporting_evidence[:2])  # æœ€åˆã®2ã¤ã®è¨¼æ‹ ã®ã¿
        if not match_reasons:
            match_reasons = ["ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæ¤œå‡º"]

        reason_text = ", ".join(match_reasons)
        if len(reason_text) > 30:
            reason_text = reason_text[:27] + "..."

        pattern_table.add_row(match.pattern.name, match.pattern.category, confidence_text, reason_text)

    console.print(pattern_table)
    console.print()

    # è©³ç´°ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒæƒ…å ±ã‚’è¡¨ç¤º
    for i, match in enumerate(pattern_matches[:3], 1):  # ä¸Šä½3ã¤ã®ã¿è©³ç´°è¡¨ç¤º
        console.print(f"[bold cyan]ãƒ‘ã‚¿ãƒ¼ãƒ³ {i}: {match.pattern.name}[/bold cyan]")
        console.print(f"  ã‚«ãƒ†ã‚´ãƒª: {match.pattern.category}")
        console.print(f"  ä¿¡é ¼åº¦: {match.confidence:.1%}")

        if hasattr(match, "extracted_context") and match.extracted_context:
            context_preview = match.extracted_context[:100]
            if len(match.extracted_context) > 100:
                context_preview += "..."
            console.print(f"  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: [dim]{context_preview}[/dim]")

        if hasattr(match, "supporting_evidence") and match.supporting_evidence:
            console.print("  æ¤œå‡ºæ ¹æ‹ :")
            for evidence in match.supporting_evidence[:3]:  # æœ€åˆã®3ã¤ã®è¨¼æ‹ 
                console.print(f"    â€¢ {evidence}")

        console.print()


def _display_detailed_fix_suggestions(fix_suggestions: list, console: Console) -> None:
    """ä¿®æ­£ææ¡ˆã‚’è©³ç´°è¡¨ç¤º

    Args:
        fix_suggestions: ä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """

    console.print("[bold]ä¿®æ­£ææ¡ˆ:[/bold]")

    # ä¿®æ­£ææ¡ˆã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã§è¡¨ç¤º
    for i, fix in enumerate(fix_suggestions, 1):
        # å„ªå…ˆåº¦ã«å¿œã˜ãŸè‰²åˆ†ã‘
        priority_colors = {"urgent": "red", "high": "yellow", "medium": "blue", "low": "dim"}
        priority = getattr(fix, "priority", "medium")
        priority_str = priority.value if hasattr(priority, "value") else str(priority)
        priority_color = priority_colors.get(priority_str.lower(), "blue")

        console.print(f"\n[bold {priority_color}]ä¿®æ­£æ¡ˆ {i}: {fix.title}[/bold {priority_color}]")
        console.print(f"  èª¬æ˜: {fix.description}")

        # ä¿¡é ¼åº¦è¡¨ç¤º
        if hasattr(fix, "confidence") and fix.confidence > 0:
            confidence_color = "green" if fix.confidence >= 0.8 else "yellow" if fix.confidence >= 0.6 else "red"
            console.print(f"  ä¿¡é ¼åº¦: [{confidence_color}]{fix.confidence:.1%}[/{confidence_color}]")

        # èƒŒæ™¯ç†ç”±ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        if hasattr(fix, "background_reason") and fix.background_reason:
            console.print(f"  [bold cyan]èƒŒæ™¯ç†ç”±:[/bold cyan] {fix.background_reason}")

        # å½±éŸ¿è©•ä¾¡ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        if hasattr(fix, "impact_assessment") and fix.impact_assessment:
            console.print(f"  [bold yellow]å½±éŸ¿è©•ä¾¡:[/bold yellow] {fix.impact_assessment}")

        # ãƒªã‚¹ã‚¯è©•ä¾¡ã¨æ¨å®šæ™‚é–“ï¼ˆè©³ç´°è¡¨ç¤ºï¼‰
        _display_risk_and_time_details(fix, console)

        # å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«
        if hasattr(fix, "code_changes") and fix.code_changes:
            files = {change.file_path for change in fix.code_changes}
            console.print(f"  å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(list(files)[:3])}")
            if len(files) > 3:
                console.print(f"    ... ä»– {len(files) - 3} ãƒ•ã‚¡ã‚¤ãƒ«")

        # å‰ææ¡ä»¶ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        if hasattr(fix, "prerequisites") and fix.prerequisites:
            console.print("  [bold magenta]å‰ææ¡ä»¶:[/bold magenta]")
            for prereq in fix.prerequisites[:3]:  # æœ€åˆã®3ã¤
                console.print(f"    â€¢ {prereq}")

        # æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        if hasattr(fix, "validation_steps") and fix.validation_steps:
            console.print("  [bold green]æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—:[/bold green]")
            for step in fix.validation_steps[:3]:  # æœ€åˆã®3ã¤
                console.print(f"    â€¢ {step}")

        # å‚è€ƒãƒªãƒ³ã‚¯
        if hasattr(fix, "references") and fix.references:
            console.print("  å‚è€ƒ:")
            for ref in fix.references[:2]:  # æœ€åˆã®2ã¤ã®ã¿
                console.print(f"    â€¢ {ref}")

    # ä¿®æ­£ææ¡ˆã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºï¼ˆåŠ¹æœã¨å®‰å…¨æ€§ã«ã‚ˆã‚‹ï¼‰
    if len(fix_suggestions) > 1:
        _display_fix_suggestions_ranking(fix_suggestions, console)


def _display_risk_and_time_details(fix_suggestion, console: Console) -> None:
    """ãƒªã‚¹ã‚¯è©•ä¾¡ã¨æ¨å®šæ™‚é–“ã®è©³ç´°è¡¨ç¤º

    Args:
        fix_suggestion: ä¿®æ­£ææ¡ˆ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    from rich.table import Table

    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®è¡¨ç¤º
    risk_level = getattr(fix_suggestion, "risk_level", "medium")
    risk_colors = {"low": "green", "medium": "yellow", "high": "red"}
    risk_color = risk_colors.get(risk_level, "yellow")
    console.print(f"  ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: [{risk_color}]{risk_level.upper()}[/{risk_color}]")

    # æ¨å®šæ™‚é–“ã®è©³ç´°è¡¨ç¤º
    estimated_time_minutes = getattr(fix_suggestion, "estimated_time_minutes", 0)
    if estimated_time_minutes > 0:
        if estimated_time_minutes < 60:
            time_str = f"{estimated_time_minutes}åˆ†"
        else:
            hours = estimated_time_minutes // 60
            minutes = estimated_time_minutes % 60
            time_str = f"{hours}æ™‚é–“{minutes}åˆ†" if minutes > 0 else f"{hours}æ™‚é–“"
        console.print(f"  æ¨å®šæ™‚é–“: {time_str}")
    elif hasattr(fix_suggestion, "estimated_effort") and fix_suggestion.estimated_effort != "ä¸æ˜":
        console.print(f"  æ¨å®šæ™‚é–“: {fix_suggestion.estimated_effort}")

    # åŠ¹æœã¨å®‰å…¨æ€§ã®ã‚¹ã‚³ã‚¢è¡¨ç¤º
    effectiveness_score = getattr(fix_suggestion, "effectiveness_score", 0.0)
    safety_score = getattr(fix_suggestion, "safety_score", 0.0)

    if effectiveness_score > 0 or safety_score > 0:
        # å°ã•ãªãƒ†ãƒ¼ãƒ–ãƒ«ã§ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
        score_table = Table(show_header=False, box=None, padding=(0, 1))
        score_table.add_column("é …ç›®", style="dim")
        score_table.add_column("ã‚¹ã‚³ã‚¢", style="bold")

        if effectiveness_score > 0:
            eff_color = "green" if effectiveness_score >= 0.8 else "yellow" if effectiveness_score >= 0.6 else "red"
            score_table.add_row("åŠ¹æœ", f"[{eff_color}]{effectiveness_score:.1%}[/{eff_color}]")

        if safety_score > 0:
            safety_color = "green" if safety_score >= 0.8 else "yellow" if safety_score >= 0.6 else "red"
            score_table.add_row("å®‰å…¨æ€§", f"[{safety_color}]{safety_score:.1%}[/{safety_color}]")

        console.print("  è©•ä¾¡ã‚¹ã‚³ã‚¢:")
        console.print(score_table)


def _display_fix_suggestions_ranking(fix_suggestions: list, console: Console) -> None:
    """ä¿®æ­£ææ¡ˆã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºï¼ˆåŠ¹æœã¨å®‰å…¨æ€§ã«ã‚ˆã‚‹ï¼‰

    Args:
        fix_suggestions: ä¿®æ­£ææ¡ˆã®ãƒªã‚¹ãƒˆ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    from rich.table import Table

    console.print("\n[bold blue]ä¿®æ­£ææ¡ˆãƒ©ãƒ³ã‚­ãƒ³ã‚° (åŠ¹æœãƒ»å®‰å…¨æ€§é †):[/bold blue]")

    ranking_table = Table(show_header=True, header_style="bold blue")
    ranking_table.add_column("é †ä½", style="cyan", width=4)
    ranking_table.add_column("ä¿®æ­£æ¡ˆ", style="white", width=25)
    ranking_table.add_column("åŠ¹æœ", style="green", width=8)
    ranking_table.add_column("å®‰å…¨æ€§", style="yellow", width=8)
    ranking_table.add_column("ãƒªã‚¹ã‚¯", style="red", width=8)
    ranking_table.add_column("ç·åˆè©•ä¾¡", style="blue", width=10)

    # ä¿®æ­£ææ¡ˆã‚’ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    scored_fixes = []
    for fix in fix_suggestions:
        effectiveness = getattr(fix, "effectiveness_score", getattr(fix, "confidence", 0.5))
        safety = getattr(fix, "safety_score", 1.0 - _calculate_risk_score(fix))
        risk_score = _calculate_risk_score(fix)
        overall = effectiveness * 0.4 + safety * 0.4 + (1.0 - risk_score) * 0.2

        scored_fixes.append((fix, effectiveness, safety, risk_score, overall))

    # ç·åˆè©•ä¾¡ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
    scored_fixes.sort(key=lambda x: x[4], reverse=True)

    for i, (fix, effectiveness, safety, risk_score, overall) in enumerate(scored_fixes[:5], 1):
        # è‰²åˆ†ã‘
        eff_color = "green" if effectiveness >= 0.8 else "yellow" if effectiveness >= 0.6 else "red"
        safety_color = "green" if safety >= 0.8 else "yellow" if safety >= 0.6 else "red"
        risk_color = "green" if risk_score <= 0.3 else "yellow" if risk_score <= 0.6 else "red"
        overall_color = "green" if overall >= 0.8 else "yellow" if overall >= 0.6 else "red"

        ranking_table.add_row(
            str(i),
            fix.title[:22] + "..." if len(fix.title) > 25 else fix.title,
            f"[{eff_color}]{effectiveness:.1%}[/{eff_color}]",
            f"[{safety_color}]{safety:.1%}[/{safety_color}]",
            f"[{risk_color}]{risk_score:.1%}[/{risk_color}]",
            f"[{overall_color}]{overall:.1%}[/{overall_color}]",
        )

    console.print(ranking_table)

    # æ¨å¥¨ä¿®æ­£æ¡ˆã®è¡¨ç¤º
    if scored_fixes:
        best_fix = scored_fixes[0][0]
        console.print(f"\n[bold green]ğŸ¯ æ¨å¥¨ä¿®æ­£æ¡ˆ: {best_fix.title}[/bold green]")

        # æ¨å¥¨ç†ç”±ã‚’è¡¨ç¤º
        reasons = []
        if scored_fixes[0][1] >= 0.8:  # åŠ¹æœãŒé«˜ã„
            reasons.append("é«˜ã„åŠ¹æœãŒæœŸå¾…ã§ãã¾ã™")
        if scored_fixes[0][2] >= 0.8:  # å®‰å…¨æ€§ãŒé«˜ã„
            reasons.append("å®‰å…¨æ€§ãŒé«˜ãä½ãƒªã‚¹ã‚¯ã§ã™")
        if scored_fixes[0][3] <= 0.3:  # ãƒªã‚¹ã‚¯ãŒä½ã„
            reasons.append("å®Ÿè£…ãƒªã‚¹ã‚¯ãŒä½ã„ã§ã™")

        if reasons:
            console.print(f"  ç†ç”±: {', '.join(reasons)}")

    console.print()


def _calculate_risk_score(fix_suggestion) -> float:
    """ä¿®æ­£ææ¡ˆã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—

    Args:
        fix_suggestion: ä¿®æ­£ææ¡ˆ

    Returns:
        ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ (0.0-1.0, é«˜ã„ã»ã©ãƒªã‚¹ã‚­ãƒ¼)
    """
    risk_score = 0.0

    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹ç›´æ¥çš„ãªãƒªã‚¹ã‚¯ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    risk_level = getattr(fix_suggestion, "risk_level", "medium")
    risk_level_scores = {"low": 0.2, "medium": 0.5, "high": 0.8}
    risk_score += risk_level_scores.get(risk_level, 0.5)

    # å„ªå…ˆåº¦ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
    priority_risks = {"urgent": 0.8, "high": 0.6, "medium": 0.3, "low": 0.1}
    priority = getattr(fix_suggestion, "priority", "medium")
    if hasattr(priority, "value"):
        priority = priority.value
    risk_score += priority_risks.get(str(priority).lower(), 0.3) * 0.3  # é‡ã¿ä»˜ã‘ã‚’èª¿æ•´

    # ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ•°ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
    if hasattr(fix_suggestion, "code_changes") and fix_suggestion.code_changes:
        file_count = len({change.file_path for change in fix_suggestion.code_changes})
        risk_score += min(file_count * 0.05, 0.2)  # é‡ã¿ä»˜ã‘ã‚’èª¿æ•´

    # æ¨å®šæ™‚é–“ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯
    estimated_time_minutes = getattr(fix_suggestion, "estimated_time_minutes", 0)
    if estimated_time_minutes > 0:
        # é•·æ™‚é–“ã®ä½œæ¥­ã»ã©ãƒªã‚¹ã‚¯ãŒé«˜ã„
        time_risk = min(estimated_time_minutes / 480.0, 0.3)  # 8æ™‚é–“ã§æœ€å¤§ãƒªã‚¹ã‚¯
        risk_score += time_risk

    return min(risk_score, 1.0)


def _display_fallback_info(result: AnalysisResult, console: Console) -> None:
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã‚’è¡¨ç¤º

    Args:
        result: åˆ†æçµæœ
        console: ã‚³ãƒ³ã‚½ãƒ¼ãƒ«
    """
    if result.status.value != "fallback":
        return

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç†ç”±ã‚’è¡¨ç¤º
    if result.fallback_reason:
        console.print(f"\n[yellow]ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç†ç”±: {result.fallback_reason}[/yellow]")

    # ãƒªãƒˆãƒ©ã‚¤æƒ…å ±ã‚’è¡¨ç¤º
    if result.retry_available:
        if result.retry_after:
            console.print(f"[blue]ğŸ’¡ {result.retry_after}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã§ãã¾ã™[/blue]")
        else:
            console.print("[blue]ğŸ’¡ ã™ãã«ãƒªãƒˆãƒ©ã‚¤ã§ãã¾ã™[/blue]")

    # ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
    if result.alternative_providers:
        providers_text = ", ".join(result.alternative_providers)
        console.print(f"[blue]ğŸ’¡ ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {providers_text}[/blue]")

    # æ“ä½œIDã‚’è¡¨ç¤ºï¼ˆãƒªãƒˆãƒ©ã‚¤ç”¨ï¼‰
    operation_id = f"fallback_{result.timestamp.strftime('%Y%m%d_%H%M%S')}"
    console.print(f"[dim]æ“ä½œID: {operation_id}[/dim]")
    console.print("[dim]ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã«ã¯: ci-run analyze --retry {operation_id}[/dim]")


def _handle_ci_helper_error(error: CIHelperError, console: Console, verbose: bool) -> None:
    """CI Helperå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†

    Args:
        error: CI Helperã‚¨ãƒ©ãƒ¼
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
    """
    from ..core.exceptions import ConfigurationError, DependencyError, ValidationError, WorkflowNotFoundError

    if isinstance(error, ConfigurationError):
        console.print(f"[red]è¨­å®šã‚¨ãƒ©ãƒ¼:[/red] {error.message}")
        console.print("[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue]")
        console.print("  â€¢ ci-run init ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆ")
        console.print("  â€¢ ci-helper.toml ã® [ai] ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª")
        console.print("  â€¢ ç’°å¢ƒå¤‰æ•°ã§APIã‚­ãƒ¼ã‚’è¨­å®š")

    elif isinstance(error, DependencyError):
        console.print(f"[red]ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼:[/red] {error.message}")
        console.print("[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue]")
        console.print("  â€¢ ci-run doctor ã§ç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯")
        console.print("  â€¢ å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

    elif isinstance(error, ValidationError):
        console.print(f"[red]å…¥åŠ›æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:[/red] {error.message}")
        console.print("[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue]")
        console.print("  â€¢ å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèª")
        console.print("  â€¢ ci-run analyze --help ã§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª")

    elif isinstance(error, WorkflowNotFoundError):
        console.print(f"[red]ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼:[/red] {error.message}")
        console.print("[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue]")
        console.print("  â€¢ ci-run test ã§ãƒ­ã‚°ã‚’ç”Ÿæˆ")
        console.print("  â€¢ --log ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ç‰¹å®šã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š")

    else:
        console.print(f"[red]CI Helperã‚¨ãƒ©ãƒ¼:[/red] {error.message}")
        if error.suggestion:
            console.print(f"[blue]ğŸ’¡ è§£æ±ºæ–¹æ³•:[/blue] {error.suggestion}")

    # è©³ç´°è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯è¿½åŠ æƒ…å ±ã‚’è¡¨ç¤º
    if verbose and hasattr(error, "details") and error.details:
        console.print(f"\n[dim]è©³ç´°: {error.details}[/dim]")


def _handle_analysis_error(error: Exception, console: Console, verbose: bool) -> None:
    """åˆ†æã‚¨ãƒ©ãƒ¼ã®å‡¦ç†

    AIå›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼ã«å¯¾ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

    Args:
        error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
        verbose: è©³ç´°è¡¨ç¤ºãƒ•ãƒ©ã‚°
    """
    from ..ai.exceptions import (
        APIKeyError,
        ConfigurationError,
        NetworkError,
        ProviderError,
        RateLimitError,
        TokenLimitError,
    )

    # ã‚¨ãƒ©ãƒ¼ã®é‡è¦åº¦ã‚’åˆ¤å®š
    error_severity = _determine_error_severity(error)
    severity_color = _get_severity_color(error_severity)

    # ã‚¨ãƒ©ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º
    console.print(f"\n[{severity_color}]{'=' * 60}[/{severity_color}]")
    console.print(f"[{severity_color}]ğŸš¨ AIåˆ†æã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ[/{severity_color}]")
    console.print(f"[{severity_color}]{'=' * 60}[/{severity_color}]")

    if isinstance(error, APIKeyError):
        _handle_api_key_error_enhanced(error, console, verbose)

    elif isinstance(error, RateLimitError):
        _handle_rate_limit_error_enhanced(error, console, verbose)

    elif isinstance(error, TokenLimitError):
        _handle_token_limit_error_enhanced(error, console, verbose)

    elif isinstance(error, NetworkError):
        _handle_network_error_enhanced(error, console, verbose)

    elif isinstance(error, ConfigurationError):
        _handle_configuration_error_enhanced(error, console, verbose)

    elif isinstance(error, ProviderError):
        _handle_provider_error_enhanced(error, console, verbose)

    else:
        _handle_generic_error_enhanced(error, console, verbose)

    # å…±é€šã®ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
    _display_error_footer(error, console, verbose)


def _determine_error_severity(error: Exception) -> str:
    """ã‚¨ãƒ©ãƒ¼ã®é‡è¦åº¦ã‚’åˆ¤å®š

    Args:
        error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼

    Returns:
        ã‚¨ãƒ©ãƒ¼ã®é‡è¦åº¦ (critical, high, medium, low)
    """
    from ..ai.exceptions import (
        APIKeyError,
        ConfigurationError,
        NetworkError,
        ProviderError,
        RateLimitError,
        SecurityError,
        TokenLimitError,
    )

    if isinstance(error, APIKeyError | SecurityError | ConfigurationError):
        return "critical"
    elif isinstance(error, RateLimitError | NetworkError):
        return "medium"
    elif isinstance(error, ProviderError | TokenLimitError):
        return "high"
    else:
        return "low"


def _get_severity_color(severity: str) -> str:
    """é‡è¦åº¦ã«å¿œã˜ãŸè‰²ã‚’å–å¾—

    Args:
        severity: ã‚¨ãƒ©ãƒ¼ã®é‡è¦åº¦

    Returns:
        Richç”¨ã®è‰²å
    """
    colors = {
        "critical": "bright_red",
        "high": "red",
        "medium": "yellow",
        "low": "blue",
    }
    return colors.get(severity, "white")


def _handle_api_key_error_enhanced(error: APIKeyError, console: Console, verbose: bool) -> None:
    """APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print(f"\n[bright_red]ğŸ”‘ APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼ ({error.provider})[/bright_red]")
    console.print(f"[red]{error.message}[/red]")

    # ç’°å¢ƒå¤‰æ•°åã‚’æ±ºå®š
    env_var_name = f"{error.provider.upper()}_API_KEY"
    if error.provider == "openai":
        env_var_name = "OPENAI_API_KEY"
    elif error.provider == "anthropic":
        env_var_name = "ANTHROPIC_API_KEY"

    console.print("\n[blue]ğŸ“‹ æ®µéšçš„è§£æ±ºæ‰‹é †:[/blue]")
    console.print(f"  1ï¸âƒ£  ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š: [cyan]export {env_var_name}=your_api_key[/cyan]")
    console.print("  2ï¸âƒ£  APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèª")
    console.print(f"  3ï¸âƒ£  {error.provider}ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§æ¨©é™ã‚’ç¢ºèª")
    console.print("  4ï¸âƒ£  è¨­å®šå¾Œã«ã‚³ãƒãƒ³ãƒ‰ã‚’å†å®Ÿè¡Œ")

    # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®è¿½åŠ æƒ…å ±
    if error.provider == "openai":
        console.print("\n[dim]ğŸ’¡ OpenAI APIã‚­ãƒ¼å–å¾—: https://platform.openai.com/api-keys[/dim]")
        console.print("[dim]ğŸ’¡ ä½¿ç”¨åˆ¶é™ç¢ºèª: https://platform.openai.com/usage[/dim]")
    elif error.provider == "anthropic":
        console.print("[dim]ğŸ’¡ Anthropic APIã‚­ãƒ¼å–å¾—: https://console.anthropic.com/[/dim]")

    # ä»£æ›¿æ‰‹æ®µã®ææ¡ˆ
    console.print("\n[green]ğŸ”„ ä»£æ›¿æ‰‹æ®µ:[/green]")
    console.print("  â€¢ åˆ¥ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è©¦ã™: [cyan]--provider local[/cyan]")
    console.print("  â€¢ å¾“æ¥ã®ãƒ­ã‚°è¡¨ç¤º: [cyan]ci-run logs --show latest[/cyan]")


def _handle_rate_limit_error_enhanced(error: RateLimitError, console: Console, verbose: bool) -> None:
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print(f"\n[yellow]â±ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ ({error.provider})[/yellow]")
    console.print(f"[yellow]{error.message}[/yellow]")

    # å¾…æ©Ÿæ™‚é–“ã®è¡¨ç¤º
    if error.retry_after:
        minutes, seconds = divmod(error.retry_after, 60)
        if minutes > 0:
            console.print(f"[blue]â° å¾…æ©Ÿæ™‚é–“: {minutes}åˆ†{seconds}ç§’[/blue]")
        else:
            console.print(f"[blue]â° å¾…æ©Ÿæ™‚é–“: {seconds}ç§’[/blue]")
    elif error.reset_time:
        console.print(f"[blue]â° åˆ¶é™ãƒªã‚»ãƒƒãƒˆ: {error.reset_time.strftime('%H:%M:%S')}[/blue]")

    console.print("\n[blue]ğŸ“‹ å¯¾å‡¦æ–¹æ³•:[/blue]")
    console.print("  1ï¸âƒ£  ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œ")
    console.print("  2ï¸âƒ£  ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨: [cyan]--model gpt-4o-mini[/cyan]")
    console.print("  3ï¸âƒ£  å…¥åŠ›ã‚’çŸ­ç¸®ã¾ãŸã¯åˆ†å‰²")
    console.print("  4ï¸âƒ£  ãƒ—ãƒ©ãƒ³ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’æ¤œè¨")

    # è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã®ææ¡ˆ
    if error.retry_after and error.retry_after <= 300:  # 5åˆ†ä»¥å†…
        console.print("\n[green]ğŸ”„ è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ãŒåˆ©ç”¨å¯èƒ½ã§ã™[/green]")
        console.print("[dim]ã‚³ãƒãƒ³ãƒ‰ã‚’å†å®Ÿè¡Œã™ã‚‹ã¨è‡ªå‹•çš„ã«å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™[/dim]")


def _handle_token_limit_error_enhanced(error: TokenLimitError, console: Console, verbose: bool) -> None:
    """ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print("\n[red]ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚¨ãƒ©ãƒ¼[/red]")
    console.print(f"[red]{error.message}[/red]")

    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®è©³ç´°è¡¨ç¤º
    usage_percentage = (error.used_tokens / error.limit) * 100
    console.print("\n[yellow]ğŸ“ˆ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨çŠ¶æ³:[/yellow]")
    console.print(f"  ä½¿ç”¨é‡: {error.used_tokens:,} / {error.limit:,} ({usage_percentage:.1f}%)")
    console.print(f"  ãƒ¢ãƒ‡ãƒ«: {error.model}")
    console.print(f"  è¶…éé‡: {error.used_tokens - error.limit:,} ãƒˆãƒ¼ã‚¯ãƒ³")

    # å‰Šæ¸›ææ¡ˆã®è¨ˆç®—
    reduction_needed = ((error.used_tokens - error.limit) / error.used_tokens) * 100
    console.print("\n[blue]ğŸ“‹ è§£æ±ºæ–¹æ³•:[/blue]")
    console.print(f"  1ï¸âƒ£  å…¥åŠ›ã‚’ç´„{reduction_needed:.1f}%å‰Šæ¸›")
    console.print("  2ï¸âƒ£  ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨: [cyan]--model gpt-4-turbo[/cyan]")
    console.print("  3ï¸âƒ£  ãƒ­ã‚°ã‚’è¦ç´„ã—ã¦ã‹ã‚‰åˆ†æ")
    console.print("  4ï¸âƒ£  è¤‡æ•°ã®å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")

    # è‡ªå‹•åœ§ç¸®ã®ææ¡ˆ
    console.print("\n[green]ğŸ—œï¸  è‡ªå‹•åœ§ç¸®æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™[/green]")
    console.print("[dim]--compress ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è‡ªå‹•çš„ã«ãƒ­ã‚°ã‚’åœ§ç¸®ã§ãã¾ã™[/dim]")


def _handle_network_error_enhanced(error: NetworkError, console: Console, verbose: bool) -> None:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print("\n[yellow]ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼[/yellow]")
    console.print(f"[yellow]{error.message}[/yellow]")

    if error.retry_count > 0:
        console.print(f"[blue]ğŸ”„ ãƒªãƒˆãƒ©ã‚¤å›æ•°: {error.retry_count}/3[/blue]")

    console.print("\n[blue]ğŸ“‹ è¨ºæ–­æ‰‹é †:[/blue]")
    console.print("  1ï¸âƒ£  ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª")
    console.print("  2ï¸âƒ£  ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç¢ºèª")
    console.print("  3ï¸âƒ£  ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šã‚’ç¢ºèª")
    console.print("  4ï¸âƒ£  DNSè¨­å®šã‚’ç¢ºèª")

    # æ¥ç¶šãƒ†ã‚¹ãƒˆã®ææ¡ˆ
    console.print("\n[green]ğŸ” æ¥ç¶šãƒ†ã‚¹ãƒˆ:[/green]")
    console.print("  â€¢ OpenAI: [cyan]curl -I https://api.openai.com[/cyan]")
    console.print("  â€¢ Anthropic: [cyan]curl -I https://api.anthropic.com[/cyan]")

    # è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æƒ…å ±
    if error.retry_count < 3:
        retry_delay = min(2**error.retry_count, 60)
        console.print(f"\n[green]ğŸ”„ è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤: {retry_delay}ç§’å¾Œã«å®Ÿè¡Œã•ã‚Œã¾ã™[/green]")


def _handle_configuration_error_enhanced(error: ConfigurationError, console: Console, verbose: bool) -> None:
    """è¨­å®šã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print("\n[red]âš™ï¸  è¨­å®šã‚¨ãƒ©ãƒ¼[/red]")
    console.print(f"[red]{error.message}[/red]")

    if error.config_key:
        console.print(f"[yellow]ğŸ”‘ å•é¡Œã®ã‚ã‚‹è¨­å®šã‚­ãƒ¼: {error.config_key}[/yellow]")

    console.print("\n[blue]ğŸ“‹ è¨­å®šä¿®å¾©æ‰‹é †:[/blue]")
    console.print("  1ï¸âƒ£  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: [cyan]ci-helper.toml[/cyan]")
    console.print("  2ï¸âƒ£  ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèª: [cyan]env | grep CI_HELPER[/cyan]")
    console.print("  3ï¸âƒ£  ç’°å¢ƒè¨ºæ–­ã‚’å®Ÿè¡Œ: [cyan]ci-run doctor[/cyan]")
    console.print("  4ï¸âƒ£  è¨­å®šã‚’å†ç”Ÿæˆ: [cyan]ci-run init[/cyan]")

    # è¨­å®šä¾‹ã®è¡¨ç¤º
    console.print("\n[green]ğŸ“ è¨­å®šä¾‹:[/green]")
    console.print("[dim][ai][/dim]")
    console.print('[dim]default_provider = "openai"[/dim]')
    console.print("[dim]cache_enabled = true[/dim]")


def _handle_provider_error_enhanced(error: ProviderError, console: Console, verbose: bool) -> None:
    """ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    console.print(f"\n[red]ğŸ”Œ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ ({error.provider})[/red]")
    console.print(f"[red]{error.message}[/red]")

    if error.details:
        console.print(f"[yellow]ğŸ“‹ è©³ç´°: {error.details}[/yellow]")

    console.print("\n[blue]ğŸ“‹ è§£æ±ºæ‰‹é †:[/blue]")
    console.print("  1ï¸âƒ£  ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šã‚’ç¢ºèª")
    console.print("  2ï¸âƒ£  APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèª")
    console.print("  3ï¸âƒ£  ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ã‚’ç¢ºèª")
    console.print("  4ï¸âƒ£  åˆ¥ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è©¦ã™")

    # ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ææ¡ˆ
    alternatives = []
    if error.provider != "openai":
        alternatives.append("openai")
    if error.provider != "anthropic":
        alternatives.append("anthropic")
    if error.provider != "local":
        alternatives.append("local")

    if alternatives:
        console.print("\n[green]ğŸ”„ ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼:[/green]")
        for alt in alternatives:
            console.print(f"  â€¢ {alt}: [cyan]--provider {alt}[/cyan]")

    # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³ç¢ºèªãƒªãƒ³ã‚¯
    status_urls = {
        "openai": "https://status.openai.com/",
        "anthropic": "https://status.anthropic.com/",
    }
    if error.provider in status_urls:
        console.print(f"\n[dim]ğŸ” ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³: {status_urls[error.provider]}[/dim]")


def _handle_generic_error_enhanced(error: Exception, console: Console, verbose: bool) -> None:
    """æ±ç”¨ã‚¨ãƒ©ãƒ¼ã®æ‹¡å¼µå‡¦ç†"""
    error_type = type(error).__name__
    console.print(f"\n[red]âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ ({error_type})[/red]")
    console.print(f"[red]{error}[/red]")

    console.print("\n[blue]ğŸ“‹ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:[/blue]")
    console.print("  1ï¸âƒ£  è©³ç´°ãƒ­ã‚°ã§ç¢ºèª: [cyan]--verbose[/cyan]")
    console.print("  2ï¸âƒ£  ç’°å¢ƒã‚’è¨ºæ–­: [cyan]ci-run doctor[/cyan]")
    console.print("  3ï¸âƒ£  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢: [cyan]ci-run clean[/cyan]")
    console.print("  4ï¸âƒ£  è¨­å®šã‚’ãƒªã‚»ãƒƒãƒˆ: [cyan]ci-run init[/cyan]")

    # ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆã®ææ¡ˆ
    console.print("\n[green]ğŸ› ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆ:[/green]")
    console.print("  å•é¡ŒãŒç¶šãå ´åˆã¯ GitHub Issues ã§å ±å‘Šã—ã¦ãã ã•ã„")
    console.print("  [cyan]https://github.com/scottlz0310/ci-helper/issues[/cyan]")


def _display_error_footer(error: Exception, console: Console, verbose: bool) -> None:
    """ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã®ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±"""
    console.print(f"\n[dim]{'â”€' * 60}[/dim]")

    # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚åˆ»
    console.print(f"[dim]â° ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}[/dim]")

    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
    console.print(f"[dim]ğŸ·ï¸  ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(error).__name__}[/dim]")

    # è©³ç´°è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’è¡¨ç¤º
    if verbose:
        console.print("\n[dim]ğŸ“Š è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:[/dim]")
        console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error!s}[/dim]")
        if hasattr(error, "__traceback__") and error.__traceback__:
            import traceback

            tb_str = "".join(traceback.format_exception(type(error), error, error.__traceback__))
            console.print(f"[dim]{tb_str}[/dim]")

    # ãƒ˜ãƒ«ãƒ—æƒ…å ±
    console.print("\n[blue]ğŸ’¡ è¿½åŠ ãƒ˜ãƒ«ãƒ—:[/blue]")
    console.print("  â€¢ ã‚³ãƒãƒ³ãƒ‰ãƒ˜ãƒ«ãƒ—: [cyan]ci-run analyze --help[/cyan]")
    console.print("  â€¢ ç’°å¢ƒè¨ºæ–­: [cyan]ci-run doctor[/cyan]")
    console.print("  â€¢ è¨­å®šã‚¬ã‚¤ãƒ‰: [cyan]ci-run init[/cyan]")

    console.print(f"[dim]{'â”€' * 60}[/dim]")


def _suggest_fallback_options(console: Console, log_file: Path | None) -> None:
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ææ¡ˆ

    AIåˆ†æãŒå¤±æ•—ã—ãŸå ´åˆã®ä»£æ›¿æ‰‹æ®µã‚’ææ¡ˆã—ã¾ã™ã€‚

    Args:
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«
        log_file: åˆ†æå¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
    """
    from rich.panel import Panel
    from rich.table import Table

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
    console.print(Panel.fit("ğŸ”„ åˆ©ç”¨å¯èƒ½ãªä»£æ›¿æ‰‹æ®µ", style="blue"))

    # å³åº§ã«å®Ÿè¡Œå¯èƒ½ãªä»£æ›¿æ‰‹æ®µ
    immediate_table = Table(title="ğŸš€ å³åº§ã«å®Ÿè¡Œå¯èƒ½", show_header=True, header_style="bold blue")
    immediate_table.add_column("æ–¹æ³•", style="cyan", width=20)
    immediate_table.add_column("ã‚³ãƒãƒ³ãƒ‰", style="green", width=35)
    immediate_table.add_column("èª¬æ˜", style="white", width=25)

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«é–¢é€£ã®ä»£æ›¿æ‰‹æ®µ
    if log_file and log_file.exists():
        immediate_table.add_row("ğŸ“„ ãƒ­ã‚°ç›´æ¥ç¢ºèª", f"cat {log_file}", "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥è¡¨ç¤º")
        immediate_table.add_row("ğŸ“‹ å¾“æ¥ãƒ­ã‚°è¡¨ç¤º", "ci-run logs --show latest", "æ•´å½¢ã•ã‚ŒãŸãƒ­ã‚°è¡¨ç¤º")
    else:
        immediate_table.add_row("ğŸ”„ æ–°è¦ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", "ci-run test", "æ–°ã—ã„ãƒ­ã‚°ã‚’ç”Ÿæˆ")
        immediate_table.add_row("ğŸ“‹ éå»ãƒ­ã‚°ç¢ºèª", "ci-run logs", "æ—¢å­˜ã®ãƒ­ã‚°ä¸€è¦§è¡¨ç¤º")

    # ç’°å¢ƒè¨ºæ–­
    immediate_table.add_row("ğŸ” ç’°å¢ƒè¨ºæ–­", "ci-run doctor", "ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯")

    console.print(immediate_table)

    # AIä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    ai_table = Table(title="ğŸ¤– AIä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", show_header=True, header_style="bold yellow")
    ai_table.add_column("ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", style="cyan", width=15)
    ai_table.add_column("ã‚³ãƒãƒ³ãƒ‰", style="green", width=40)
    ai_table.add_column("ç‰¹å¾´", style="white", width=25)

    ai_table.add_row("OpenAI", "ci-run analyze --provider openai", "é«˜ç²¾åº¦ã€å¤šæ©Ÿèƒ½")
    ai_table.add_row("Anthropic", "ci-run analyze --provider anthropic", "é•·æ–‡å¯¾å¿œã€å®‰å…¨æ€§é‡è¦–")
    ai_table.add_row("ãƒ­ãƒ¼ã‚«ãƒ«LLM", "ci-run analyze --provider local", "ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã€ç„¡æ–™")

    console.print(ai_table)

    # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    troubleshoot_table = Table(title="ğŸ§¹ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", show_header=True, header_style="bold red")
    troubleshoot_table.add_column("å•é¡Œ", style="cyan", width=20)
    troubleshoot_table.add_column("è§£æ±ºã‚³ãƒãƒ³ãƒ‰", style="green", width=35)
    troubleshoot_table.add_column("åŠ¹æœ", style="white", width=25)

    troubleshoot_table.add_row("ã‚­ãƒ£ãƒƒã‚·ãƒ¥å•é¡Œ", "ci-run clean --cache-only", "AIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢")
    troubleshoot_table.add_row("å¤ã„ãƒ­ã‚°å•é¡Œ", "ci-run clean --logs-only", "å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤")
    troubleshoot_table.add_row("è¨­å®šå•é¡Œ", "ci-run init", "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆ")
    troubleshoot_table.add_row("å…¨ä½“ãƒªã‚»ãƒƒãƒˆ", "ci-run clean --all", "å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢")

    console.print(troubleshoot_table)

    # æ®µéšçš„å¾©æ—§æ‰‹é †
    console.print(Panel.fit("ğŸ“‹ æ®µéšçš„å¾©æ—§æ‰‹é †", style="green"))
    console.print("[bold green]1. åŸºæœ¬è¨ºæ–­[/bold green]")
    console.print("   [cyan]ci-run doctor[/cyan] - ç’°å¢ƒã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯")
    console.print()
    console.print("[bold green]2. è¨­å®šç¢ºèª[/bold green]")
    console.print("   [cyan]ci-run init[/cyan] - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿæˆ")
    console.print()
    console.print("[bold green]3. ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼[/bold green]")
    console.print("   [cyan]ci-run analyze --provider local[/cyan] - ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è©¦ã™")
    console.print()
    console.print("[bold green]4. å¾“æ¥æ‰‹æ³•[/bold green]")
    console.print("   [cyan]ci-run logs --show latest[/cyan] - å¾“æ¥ã®ãƒ­ã‚°è¡¨ç¤º")

    # ç·Šæ€¥æ™‚ã®é€£çµ¡å…ˆ
    console.print(Panel.fit("ğŸ†˜ ç·Šæ€¥æ™‚ã®å¯¾å¿œ", style="red"))
    console.print("[bold red]å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆ:[/bold red]")
    console.print("  ğŸ“§ GitHub Issues: [cyan]https://github.com/scottlz0310/ci-helper/issues[/cyan]")
    console.print("  ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: [cyan]https://github.com/scottlz0310/ci-helper/docs[/cyan]")
    console.print("  ğŸ” è©³ç´°ãƒ˜ãƒ«ãƒ—: [cyan]ci-run analyze --help[/cyan]")

    # è‡ªå‹•å¾©æ—§ã®ææ¡ˆ
    console.print(Panel.fit("ğŸ¤– è‡ªå‹•å¾©æ—§ã‚ªãƒ—ã‚·ãƒ§ãƒ³", style="blue"))
    console.print("[bold blue]è‡ªå‹•å¾©æ—§ã‚’è©¦ã—ã¾ã™ã‹ï¼Ÿ[/bold blue]")
    console.print("  Y: åŸºæœ¬çš„ãªä¿®å¾©ã‚’è‡ªå‹•å®Ÿè¡Œ")
    console.print("  N: æ‰‹å‹•ã§å¯¾å‡¦")
    console.print("  H: è©³ç´°ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹å ´åˆã®æº–å‚™ï¼ˆå®Ÿè£…ã¯åˆ¥é€”ï¼‰
    console.print("\n[dim]ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä¸Šè¨˜ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„[/dim]")


async def _save_partial_analysis_state(
    ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, error: Exception
) -> None:
    """éƒ¨åˆ†çš„ãªåˆ†æçŠ¶æ…‹ã‚’ä¿å­˜

    Args:
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        log_content: ãƒ­ã‚°å†…å®¹
        options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
    """
    try:
        from datetime import datetime

        operation_id = f"failed_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½¿ç”¨ã—ã¦éƒ¨åˆ†çš„ãªçµæœã‚’ä¿å­˜
        if hasattr(ai_integration, "fallback_handler"):
            await ai_integration.fallback_handler._save_partial_result(
                operation_id,
                {
                    "error_type": type(error).__name__,
                    "error_message": str(error),
                    "log_content": log_content[:1000],  # æœ€åˆã®1000æ–‡å­—ã®ã¿ä¿å­˜
                    "options": {
                        "provider": options.provider,
                        "model": options.model,
                        "output_format": options.output_format,
                    },
                    "retry_available": True,
                },
            )
    except Exception:
        # éƒ¨åˆ†ä¿å­˜ã®å¤±æ•—ã¯ç„¡è¦–
        pass


async def _attempt_automatic_recovery(
    error: Exception, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """è‡ªå‹•å¾©æ—§ã‚’è©¦è¡Œ

    Args:
        error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
        ai_integration: AIçµ±åˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        log_content: ãƒ­ã‚°å†…å®¹
        options: åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«

    Returns:
        å¾©æ—§æˆåŠŸæ™‚ã®åˆ†æçµæœã€å¤±æ•—æ™‚ã¯None
    """
    from ..ai.exceptions import NetworkError, ProviderError, RateLimitError, TokenLimitError

    console.print("\n[blue]ğŸ”„ è‡ªå‹•å¾©æ—§ã‚’è©¦è¡Œä¸­...[/blue]")

    try:
        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå¾©æ—§æˆ¦ç•¥
        if isinstance(error, TokenLimitError):
            return await _recover_from_token_limit(error, ai_integration, log_content, options, console)
        elif isinstance(error, RateLimitError):
            return await _recover_from_rate_limit(error, ai_integration, log_content, options, console)
        elif isinstance(error, NetworkError):
            return await _recover_from_network_error(error, ai_integration, log_content, options, console)
        elif isinstance(error, ProviderError):
            return await _recover_from_provider_error(error, ai_integration, log_content, options, console)
        else:
            return await _recover_from_generic_error(error, ai_integration, log_content, options, console)

    except Exception as recovery_error:
        console.print(f"[red]è‡ªå‹•å¾©æ—§ã«å¤±æ•—ã—ã¾ã—ãŸ: {recovery_error}[/red]")
        return None


async def _recover_from_token_limit(
    error: TokenLimitError, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å¾©æ—§"""
    console.print("[yellow]ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•å¾©æ—§ã‚’å®Ÿè¡Œä¸­...[/yellow]")

    # ãƒ­ã‚°å†…å®¹ã‚’åœ§ç¸®
    try:
        from ..core.log_compressor import LogCompressor

        compressor = LogCompressor(target_tokens=error.limit // 2)  # åˆ¶é™ã®åŠåˆ†ã‚’ç›®æ¨™
        compressed_content = compressor.compress_log(log_content)

        console.print(f"[green]âœ“ ãƒ­ã‚°ã‚’åœ§ç¸®ã—ã¾ã—ãŸ ({len(log_content)} â†’ {len(compressed_content)} æ–‡å­—)[/green]")

        # åœ§ç¸®ã•ã‚ŒãŸãƒ­ã‚°ã§å†è©¦è¡Œ
        result = await ai_integration.analyze_log(compressed_content, options)
        console.print("[green]âœ“ åœ§ç¸®ãƒ­ã‚°ã§ã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
        return result

    except Exception as e:
        console.print(f"[red]âœ— ãƒ­ã‚°åœ§ç¸®ã«ã‚ˆã‚‹å¾©æ—§ã«å¤±æ•—: {e}[/red]")

    # ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ã§è©¦è¡Œ
    try:
        smaller_models = {
            "gpt-4o": "gpt-4o-mini",
            "gpt-4-turbo": "gpt-4o-mini",
            "claude-3-5-sonnet-20241022": "claude-3-5-haiku-20241022",
        }

        if options.model and options.model in smaller_models:
            console.print(f"[blue]ğŸ”„ ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ: {smaller_models[options.model]}[/blue]")
            options.model = smaller_models[options.model]
            result = await ai_integration.analyze_log(log_content, options)
            console.print("[green]âœ“ å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
            return result

    except Exception as e:
        console.print(f"[red]âœ— å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã®å¾©æ—§ã«å¤±æ•—: {e}[/red]")

    return None


async def _recover_from_rate_limit(
    error: RateLimitError, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å¾©æ—§"""
    console.print("[yellow]â±ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•å¾©æ—§ã‚’å®Ÿè¡Œä¸­...[/yellow]")

    # çŸ­æ™‚é–“ã®åˆ¶é™ã®å ´åˆã¯å¾…æ©Ÿ
    if error.retry_after and error.retry_after <= 60:  # 1åˆ†ä»¥å†…
        console.print(f"[blue]â° {error.retry_after}ç§’é–“å¾…æ©Ÿä¸­...[/blue]")

        import asyncio

        from rich.progress import Progress, SpinnerColumn, TextColumn, TimeElapsedColumn

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            TimeElapsedColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("ãƒ¬ãƒ¼ãƒˆåˆ¶é™è§£é™¤ã¾ã§å¾…æ©Ÿä¸­...", total=error.retry_after)
            await asyncio.sleep(error.retry_after)
            progress.update(task, completed=error.retry_after)

        try:
            result = await ai_integration.analyze_log(log_content, options)
            console.print("[green]âœ“ å¾…æ©Ÿå¾Œã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
            return result
        except Exception as e:
            console.print(f"[red]âœ— å¾…æ©Ÿå¾Œã®å†è©¦è¡Œã«å¤±æ•—: {e}[/red]")

    # ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§è©¦è¡Œ
    alternative_providers = ["openai", "anthropic", "local"]
    current_provider = options.provider or "openai"

    for provider in alternative_providers:
        if provider != current_provider:
            try:
                console.print(f"[blue]ğŸ”„ ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§è©¦è¡Œ: {provider}[/blue]")
                options.provider = provider
                result = await ai_integration.analyze_log(log_content, options)
                console.print(f"[green]âœ“ {provider}ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
                return result
            except Exception as e:
                console.print(f"[yellow]âš ï¸  {provider}ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã‚‚å¤±æ•—: {e}[/yellow]")
                continue

    return None


async def _recover_from_network_error(
    error: NetworkError, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å¾©æ—§"""
    console.print("[yellow]ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•å¾©æ—§ã‚’å®Ÿè¡Œä¸­...[/yellow]")

    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
    max_retries = 3
    for attempt in range(max_retries):
        if attempt > 0:
            delay = min(2**attempt, 30)  # æœ€å¤§30ç§’
            console.print(f"[blue]â° {delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (è©¦è¡Œ {attempt + 1}/{max_retries})[/blue]")

            import asyncio

            await asyncio.sleep(delay)

        try:
            result = await ai_integration.analyze_log(log_content, options)
            console.print(f"[green]âœ“ ãƒªãƒˆãƒ©ã‚¤ {attempt + 1} ã§åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
            return result
        except NetworkError as e:
            console.print(f"[yellow]âš ï¸  ãƒªãƒˆãƒ©ã‚¤ {attempt + 1} å¤±æ•—: {e}[/yellow]")
            if attempt == max_retries - 1:
                console.print("[red]âœ— å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ã¾ã—ãŸ[/red]")
        except Exception as e:
            console.print(f"[red]âœ— ãƒªãƒˆãƒ©ã‚¤ä¸­ã«åˆ¥ã®ã‚¨ãƒ©ãƒ¼: {e}[/red]")
            break

    return None


async def _recover_from_provider_error(
    error: ProviderError, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å¾©æ—§"""
    console.print(f"[yellow]ğŸ”Œ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ ({error.provider}) ã®è‡ªå‹•å¾©æ—§ã‚’å®Ÿè¡Œä¸­...[/yellow]")

    # ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§è©¦è¡Œ
    alternative_providers = ["openai", "anthropic", "local"]
    failed_provider = error.provider

    for provider in alternative_providers:
        if provider != failed_provider:
            try:
                console.print(f"[blue]ğŸ”„ ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§è©¦è¡Œ: {provider}[/blue]")
                options.provider = provider
                result = await ai_integration.analyze_log(log_content, options)
                console.print(f"[green]âœ“ {provider}ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
                return result
            except Exception as e:
                console.print(f"[yellow]âš ï¸  {provider}ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã‚‚å¤±æ•—: {e}[/yellow]")
                continue

    console.print("[red]âœ— å…¨ã¦ã®ä»£æ›¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å¤±æ•—ã—ã¾ã—ãŸ[/red]")
    return None


async def _recover_from_generic_error(
    error: Exception, ai_integration: AIIntegration, log_content: str, options: AnalyzeOptions, console: Console
) -> AnalysisResult | None:
    """æ±ç”¨ã‚¨ãƒ©ãƒ¼ã‹ã‚‰ã®å¾©æ—§"""
    console.print(f"[yellow]âŒ æ±ç”¨ã‚¨ãƒ©ãƒ¼ ({type(error).__name__}) ã®è‡ªå‹•å¾©æ—§ã‚’å®Ÿè¡Œä¸­...[/yellow]")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹ã«ã—ã¦å†è©¦è¡Œ
    try:
        console.print("[blue]ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹ã«ã—ã¦å†è©¦è¡Œ...[/blue]")
        options.use_cache = False
        result = await ai_integration.analyze_log(log_content, options)
        console.print("[green]âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã§ã®åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
        return result
    except Exception as e:
        console.print(f"[yellow]âš ï¸  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã§ã‚‚å¤±æ•—: {e}[/yellow]")

    # å¾“æ¥ã®ãƒ­ã‚°è¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        console.print("[blue]ğŸ”„ å¾“æ¥ã®ãƒ­ã‚°åˆ†æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...[/blue]")
        fallback_result = await ai_integration.fallback_handler.handle_analysis_failure(error, log_content, options)
        console.print("[green]âœ“ å¾“æ¥ã®ãƒ­ã‚°åˆ†æãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
        return fallback_result
    except Exception as e:
        console.print(f"[red]âœ— ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æã‚‚å¤±æ•—: {e}[/red]")

    return None


def _offer_interactive_recovery(console: Console) -> str:
    """å¯¾è©±çš„ãªå¾©æ—§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›

    Args:
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«

    Returns:
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠ ('auto', 'manual', 'skip')
    """
    from rich.panel import Panel
    from rich.prompt import Prompt

    console.print(Panel.fit("ğŸ¤– è‡ªå‹•å¾©æ—§ã‚ªãƒ—ã‚·ãƒ§ãƒ³", style="blue"))
    console.print("[bold blue]ã©ã®ã‚ˆã†ã«å¯¾å‡¦ã—ã¾ã™ã‹ï¼Ÿ[/bold blue]")
    console.print("  [green]A[/green] - è‡ªå‹•å¾©æ—§ã‚’è©¦è¡Œ")
    console.print("  [yellow]M[/yellow] - æ‰‹å‹•ã§å¯¾å‡¦")
    console.print("  [red]S[/red] - ã‚¹ã‚­ãƒƒãƒ—ã—ã¦çµ‚äº†")

    choice = Prompt.ask("é¸æŠã—ã¦ãã ã•ã„", choices=["A", "M", "S", "a", "m", "s"], default="A").upper()

    choice_map = {"A": "auto", "M": "manual", "S": "skip"}

    return choice_map.get(choice, "auto")


def _validate_analysis_environment(config: Config, console: Console) -> bool:
    """åˆ†æç’°å¢ƒã®äº‹å‰æ¤œè¨¼

    AIåˆ†æã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ç’°å¢ƒãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚

    Args:
        config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        console: Richã‚³ãƒ³ã‚½ãƒ¼ãƒ«

    Returns:
        ç’°å¢ƒãŒæœ‰åŠ¹ã‹ã©ã†ã‹
    """
    issues = []
    warnings = []

    # AIè¨­å®šã®å­˜åœ¨ç¢ºèª
    try:
        ai_config = config.get_ai_config()
        if not ai_config:
            warnings.append("AIè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ï¼‰")
        elif isinstance(ai_config, dict) and not ai_config:
            warnings.append("AIè¨­å®šãŒç©ºã§ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ï¼‰")
    except Exception:
        warnings.append("AIè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ï¼‰")

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ç¢ºèª
    try:
        default_provider = config.get_default_ai_provider()
        if default_provider and default_provider != "local":
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®APIã‚­ãƒ¼ã®ã¿ãƒã‚§ãƒƒã‚¯
            try:
                api_key = config.get_ai_provider_api_key(default_provider)
                if not api_key:
                    issues.append(f"{default_provider}ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                elif len(api_key) < 10:
                    warnings.append(f"{default_provider}ã®APIã‚­ãƒ¼ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            except Exception:
                issues.append(f"{default_provider}ã®APIã‚­ãƒ¼å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
    except Exception:
        warnings.append("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")

    # è­¦å‘ŠãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤ºï¼ˆã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ï¼‰
    if warnings:
        console.print("[yellow]âš ï¸  è­¦å‘Š:[/yellow]")
        for warning in warnings:
            console.print(f"  â€¢ {warning}")

    # å•é¡ŒãŒã‚ã‚‹å ´åˆã¯è©³ç´°ãªã‚¨ãƒ©ãƒ¼è¡¨ç¤º
    if issues:
        console.print("[red]âŒ ç’°å¢ƒè¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™:[/red]")
        for i, issue in enumerate(issues, 1):
            console.print(f"  {i}. {issue}")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’å–å¾—
        try:
            default_provider = config.get_default_ai_provider()
        except Exception:
            default_provider = "openai"

        console.print("\n[blue]ğŸ’¡ æ®µéšçš„ãªè§£æ±ºæ–¹æ³•:[/blue]")
        console.print("  1ï¸âƒ£  APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š:")
        if default_provider == "openai":
            console.print("     [cyan]export OPENAI_API_KEY=your_key[/cyan]")
        elif default_provider == "anthropic":
            console.print("     [cyan]export ANTHROPIC_API_KEY=your_key[/cyan]")
        else:
            console.print(f"     [cyan]export {default_provider.upper()}_API_KEY=your_key[/cyan]")
        console.print("  2ï¸âƒ£  ã¾ãŸã¯åˆ¥ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨:")
        console.print("     [cyan]ci-run analyze --provider local[/cyan] (APIã‚­ãƒ¼ä¸è¦)")
        console.print("  3ï¸âƒ£  [cyan]ci-run init[/cyan] ã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆ")
        console.print("  4ï¸âƒ£  [cyan]ci-run doctor[/cyan] ã§è©³ç´°ãªç’°å¢ƒãƒã‚§ãƒƒã‚¯")
        return False

    return True
